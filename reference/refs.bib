
@article{1DTransformMotionResidual,
  title = {1-d Transforms for the Motion Compensation Residual},
  author = {Kamisli, Fatih and Lim, Jae S.},
  year = {2011},
  month = apr,
  volume = {20},
  pages = {1036--1046},
  issn = {1941-0042},
  doi = {10.1109/TIP.2010.2083675},
  abstract = {Transforms used in image coding are also commonly used to compress prediction residuals in video coding. Prediction residuals have different spatial characteristics from images, and it is useful to develop transforms that are adapted to prediction residuals. In this paper, we explore the differences between the characteristics of images and motion compensated prediction residuals by analyzing their local anisotropic characteristics and develop transforms adapted to the local anisotropic characteristics of these residuals. The analysis indicates that many regions of motion compensated prediction residuals have 1-D anisotropic characteristics and we propose to use 1-D directional transforms for these regions. We present experimental results with one example set of such transforms within the H.264/AVC codec and the results indicate that the proposed transforms can improve the compression efficiency of motion compensated prediction residuals over conventional transforms.},
  annotation = {è¿åŠ¨æ®‹å·®å…·æœ‰æ²¿æŸæ–¹å‘çš„ç›¸å…³æ€§ ç”¨1D-DCT},
  file = {E\:\\Documents\\Zotero\\storage\\ELI6JURD\\2011 - 1-D Transforms for the Motion Compensation Residual - Kamisli å’Œ Lim.pdf;E\:\\Documents\\Zotero\\storage\\TRVB35HQ\\5594636.html},
  journal = {IEEE Transactions on Image Processing},
  keywords = {1D directional transforms,Algorithms,Artifacts,compression efficiency,Correlation,discrete cosine transforms,Discrete cosine transforms,Discrete cosine transforms (DCTs),Discrete wavelet transforms,H.264/AVC codec,image coding,Image coding,Image edge detection,Image Enhancement,Image Interpretation; Computer-Assisted,Information Storage and Retrieval,local anisotropic characteristics,Mathematical model,Motion,motion compensation,motion compensation (MC),motion compensation residual,Pattern Recognition; Automated,prediction residuals,Reproducibility of Results,Sensitivity and Specificity,video coding,Video Recording},
  number = {4}
}

@misc{BeginLatexGithubQuickStart,
  title = {Luong-Komorebi/{{Begin}}-Latex-in-Minutes},
  author = {Vo, Luong},
  year = {2021},
  month = mar,
  abstract = {ğŸ“œ Brief Intro to LaTeX for beginners that helps you use LaTeX with ease.},
  annotation = {latex å…¥é—¨ æ•™å­¦ github repo},
  keywords = {basic,beginners,fast,guide,latex,latex-editor,latex-in-minutes,simple}
}

@book{BookHEVCChinese,
  title = {{æ–°ä¸€ä»£é«˜æ•ˆè§†é¢‘ç¼–ç H.265/HEVC}},
  author = {{ä¸‡å¸…} and {æ¨ä»˜æ­£}},
  year = {2014},
  publisher = {{ç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾}},
  address = {{åŒ—äº¬}},
  annotation = {HEVCä¸­æ–‡ä¹¦ OCLC: 917424983},
  file = {E\:\\Documents\\Zotero\\storage\\RK9HRP9E\\æ–°ä¸€ä»£é«˜æ•ˆè§†é¢‘ç¼–ç H.265 HEVC  åŸç†ã€æ ‡å‡†ä¸å®ç°_ä¸‡å¸…ï¼Œæ¨ä»˜æ­£ç¼–è‘—_åŒ—äº¬ï¼šç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾_2014.12_13661231_P387.pdf},
  isbn = {978-7-121-24699-9},
  language = {Chinese}
}

@book{BookHEVCEnglish,
  title = {High {{Efficiency Video Coding}} ({{HEVC}}): {{Algorithms}} and {{Architectures}}},
  shorttitle = {High {{Efficiency Video Coding}} ({{HEVC}})},
  editor = {Sze, Vivienne and Budagavi, Madhukar and Sullivan, Gary J.},
  year = {2014},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-06895-4},
  annotation = {HEVCè‹±æ–‡ä¹¦},
  file = {E\:\\Documents\\Zotero\\storage\\9W4GANJZ\\2014 - High Efficiency Video Coding (HEVC) Algorithms and Architectures - Sze ç­‰ã€‚.pdf},
  isbn = {978-3-319-06894-7 978-3-319-06895-4},
  language = {en},
  series = {Integrated {{Circuits}} and {{Systems}}}
}

@article{CoefficientScanBinGolombRice,
  title = {Transform Coefficient Coding in {{HEVC}}},
  author = {Sole, J. and Joshi, R. and Nguyen, N. and Ji, T. and Karczewicz, M. and Clare, G. and Henry, F. and Duenas, A.},
  year = {2012},
  month = dec,
  volume = {22},
  pages = {1765--1777},
  issn = {1558-2205},
  doi = {10.1109/TCSVT.2012.2223055},
  abstract = {This paper describes transform coefficient coding in the draft international standard of High Efficiency Video Coding (HEVC) specification and the driving motivations behind its design. Transform coefficient coding in HEVC encompasses the scanning patterns and coding methods for the last significant coefficient, significance map, coefficient levels, and sign data. Special attention is paid to the new methods of last significant coefficient coding, multilevel significance maps, high-throughput binarization, and sign data hiding. Experimental results are provided to evaluate the performance of transform coefficient coding in HEVC.},
  annotation = {å¾…ç¼–ç ç³»æ•° äºŒå€¼åŒ– æ‰«æ å“¥ä¼¦å¸ƒ è±æ–¯},
  file = {E\:\\Documents\\Zotero\\storage\\FGGUIEBA\\2012 - Transform Coefficient Coding in HEVC - Sole ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\REQEIKL2\\6324418.html},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  keywords = {coefficient levels,data encapsulation,draft international standard,Encoding,HEVC specification,high efficiency video coding,High Efficiency Video Coding (HEVC),high throughput entropy coder,high-throughput binarization,last significant coefficient coding,multilevel significance maps,scanning patterns,sign data hiding,Throughput,transform coding,transform coefficient coding,Transforms,video coding,Video coding},
  number = {12}
}

@article{CrossComponentPredictionCCLM,
  title = {Enhanced Cross-Component Linear Model for Chroma Intra-Prediction in Video Coding},
  author = {Zhang, Kai and Chen, Jianle and Zhang, Li and Li, Xiang and Karczewicz, Marta},
  year = {2018},
  month = aug,
  volume = {27},
  pages = {3983--3997},
  issn = {1941-0042},
  doi = {10.1109/TIP.2018.2830640},
  abstract = {Cross-component linear model (CCLM) for chroma intra-prediction is a promising coding tool in the joint exploration model (JEM) developed by the Joint Video Exploration Team (JVET). CCLM assumes a linear correlation between the luma and chroma components in a coding block. With this assumption, the chroma components can be predicted by the linear model (LM) mode, which utilizes the reconstructed neighboring samples to derive parameters of a linear model by linear regression. This paper presents three new methods to further improve the coding efficiency of CCLM. First, we introduce a multi-model CCLM (MM-CCLM) approach, which applies more than one linear model to a coding block. With MM-CCLM, reconstructed neighboring luma and chroma samples of the current block are classified into several groups, and a particular set of linear model parameters is derived for each group. The reconstructed luma samples of the current block are also classified to predict the associated chroma samples with the corresponding linear model. Second, we propose a multi-filter CCLM (MF-CCLM) technique, which allows the encoder to select the optimal down-sampling filter for the luma component with the 4:2:0 color format. Third, we present an LM-angular prediction method, which synthesizes the angular intra-prediction and the MM-CCLM intra-prediction into a new chroma intra-coding mode. Simulation results show that the BD-rate savings of 0.55\%, 4.66\%, and 5.08\% on average for Y, Cb, and Cr components, respectively, are achieved in all intra-configurations with the proposed three methods. MM-CCLM and MF-CCLM have been adopted into the JEM by JVET.},
  annotation = {äº®åº¦é¢„æµ‹è‰²å·® 3ä¸ªçº¿æ€§æ‹Ÿåˆæ¨¡å‹},
  file = {E\:\\Documents\\Zotero\\storage\\PLI72HHI\\2018 - Enhanced Cross-Component Linear Model for Chroma Intra-Prediction in Video Coding - Zhang ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\NALNIH5K\\8350031.html},
  journal = {IEEE Transactions on Image Processing},
  keywords = {angular intraprediction,associated chroma samples,BD-rate savings,chroma components,chroma intra-prediction,chroma intracoding mode,chroma intraprediction,coding block,coding efficiency,coding tool,Correlation,Cr components,Cross-component linear model,current block,enhanced cross-component linear model,High efficiency video coding,image classification,Image coding,image colour analysis,image filtering,image reconstruction,Image reconstruction,intraconfigurations,JEM,joint exploration model,Joint Video Exploration Team,JVET,linear correlation,linear model mode,linear model parameters,linear regression,Linear regression,LM,LM-angular prediction method,luma component,MF-CCLM intraprediction,MM-CCLM,multi-filter,multi-model,multifilter CCLM,multimodel CCLM,optimal down-sampling filter,Predictive models,reconstructed luma samples,reconstructed neighboring samples,regression analysis,video coding,Video coding},
  number = {8}
}

@article{DCTCoefficientMathAnalysis,
  title = {A Mathematical Analysis of the {{DCT}} Coefficient Distributions for Images},
  author = {Lam, E. Y. and Goodman, J. W.},
  year = {2000},
  month = oct,
  volume = {9},
  pages = {1661--1666},
  issn = {1941-0042},
  doi = {10.1109/83.869177},
  abstract = {Over the past two decades, there have been various studies on the distributions of the DCT coefficients for images. However, they have concentrated only on fitting the empirical data from some standard pictures with a variety of well-known statistical distributions, and then comparing their goodness of fit. The Laplacian distribution is the dominant choice balancing simplicity of the model and fidelity to the empirical data. Yet, to the best of our knowledge, there has been no mathematical justification as to what gives rise to this distribution. We offer a rigorous mathematical analysis using a doubly stochastic model of the images, which not only provides the theoretical explanations necessary, but also leads to insights about various other observations from the literature. This model also allows us to investigate how certain changes in the image statistics could affect the DCT coefficient distributions.},
  annotation = {DCT ç³»æ•° æ•°å­¦åˆ†æ},
  file = {E\:\\Documents\\Zotero\\storage\\7JSMWCYC\\2000 - A mathematical analysis of the DCT coefficient distributions for images - Lam å’Œ Goodman.pdf},
  journal = {IEEE Transactions on Image Processing},
  keywords = {central limit theorem,DCT coefficient distributions,discrete cosine transforms,Discrete cosine transforms,doubly stochastic model,empirical data,Gaussian distribution,Histograms,image coding,Image coding,image statistics,Laplace equations,Laplacian distribution,mathematical analysis,Mathematical analysis,Mathematical model,standard pictures,statistical distributions,Statistical distributions,stochastic processes,Stochastic processes,Testing,transform coding},
  number = {10}
}

@inproceedings{GeneticAlgorithmPixelCompressYiChuanSuanFa,
  title = {Image Compression Based on Genetic Algorithm Optimization},
  booktitle = {2015 2nd {{World Symposium}} on {{Web Applications}} and {{Networking}} ({{WSWAN}})},
  author = {Omari, Mohammed and Yaichi, Salah},
  year = {2015},
  month = mar,
  pages = {1--5},
  doi = {10.1109/WSWAN.2015.7210304},
  abstract = {Image compression has attracted a lot of research since the beginning of Internet era and telecommunication. Enhancing image compression quality and ratio was achieved through several approaches such as neural networks and discrete transforms. However, other heuristic and bio-inspired methods such as genetic algorithms are still under experimentation. In this paper, we introduced a new image compression mechanism based on exploiting the relationship between fractional numbers and their corresponding quotient representation. Each sub-image is mapped to a fractional number based on the RGB representation, and then reduced to an efficient quotient. The appeal of using genetic algorithms is explained by the massive search to find a close fraction that is reduced to short quotient. Our method showed a considerable compression ratio when the least significant bits of each byte are altered, hence, the image quality is preserved while achieving high compression ratio.},
  annotation = {é—ä¼ ç®—æ³•å‹ç¼©åƒç´ æ•°å€¼},
  file = {E\:\\Documents\\Zotero\\storage\\U96UTKKM\\Omari å’Œ Yaichi - 2015 - Image compression based on genetic algorithm optim.pdf;E\:\\Documents\\Zotero\\storage\\FLZGVK5X\\7210304.html},
  keywords = {Biological cells,data compression,Fractal image,fractional numbers,genetic algorithm optimization,genetic algorithms,Genetic algorithms,image coding,Image coding,image colour analysis,image compression quality enhancement,image compression ratio enhancement,image representation,Internet era,least significant bits,lossy compression,number theory,quotient representation,rational numbers,RGB representation,Sociology,Statistics,telecommunication,Wavelet transforms}
}

@article{H264Overview,
  title = {The h.264/{{MPEG4}} Advanced Video Coding Standard and Its Applications},
  author = {Marpe, D. and Wiegand, T. and Sullivan, G. J.},
  year = {2006},
  month = aug,
  volume = {44},
  pages = {134--143},
  issn = {1558-1896},
  doi = {10.1109/MCOM.2006.1678121},
  abstract = {H.264/MPEG4-AVC is the latest video coding standard of the ITU-T video coding experts group (VCEG) and the ISO/IEC moving picture experts group (MPEG). H.264/MPEG4-AVC has recently become the most widely accepted video coding standard since the deployment of MPEG2 at the dawn of digital television, and it may soon overtake MPEG2 in common use. It covers all common video applications ranging from mobile services and videoconferencing to IPTV, HDTV, and HD video storage. This article discusses the technology behind the new H.264/MPEG4-AVC standard, focusing on the main distinct features of its core coding technology and its first set of extensions, known as the fidelity range extensions (FRExt). In addition, this article also discusses the current status of adoption and deployment of the new standard in various application areas},
  annotation = {H.264ç»¼è¿°å’Œæ ‡å‡†},
  journal = {IEEE Communications Magazine},
  keywords = {core coding technology,Digital TV,fidelity range extensions,H.264-MPEG4 advanced video coding standard,HD video storage,HDTV,High definition video,IEC standards,IPTV,ISO standards,ISO-IEC moving picture experts group,ITU-T video coding experts group,mobile services,MPEG 4 Standard,MPEG standards,telecommunication services,Teleconferencing,video coding,Video coding,videoconferencing},
  number = {8}
}

@article{H264TwoLayerLosslessCoding,
  title = {Improved h.264/{{AVC}} Lossless Intra Coding with Two-Layered Residual Coding ({{TRC}})},
  author = {{Seung-Hwan Kim} and {Je-Won Kang} and Kuo, C.-C Jay},
  year = {2011},
  month = jul,
  volume = {21},
  pages = {1005--1010},
  issn = {1051-8215, 1558-2205},
  doi = {10.1109/TCSVT.2011.2133170},
  abstract = {A lossless image coding method, known as the two-layered residual coding (TRC) scheme, is proposed in this letter. After the H.264/AVC lossy intra prediction, we propose an advanced scheme for residual coding, which consists of two residual coders in cascade. The first-layer residual coder is conducted via transform and quantization with a coarser quantization parameter. The second-layer residual coder is a bitplane coding method. It is shown experimentally that the TRC scheme outperforms the H.264/AVC lossless intra coding with an averaged bit rate saving of about 24\%.},
  annotation = {ä¸¤å±‚æ®‹å·®ç¼–ç ï¼Œåœ¨æœ‰æŸçš„åŸºç¡€ä¸Šå¥—ä¸€å±‚ä¿®æ­£å€¼çš„ç¼–ç ï¼Œå®ç°æ— æŸï¼ˆH.264ï¼‰},
  file = {E\:\\Documents\\Zotero\\storage\\2CPXH2RJ\\2011 - Improved H.264AVC Lossless Intra Coding With Two-Layered Residual Coding (TRC) - Seung-Hwan Kim ç­‰ã€‚.pdf},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  language = {en},
  number = {7}
}

@inproceedings{HEVCCommonTestConditionsCTC,
  title = {Common Test Conditions and Software Reference Configurations},
  booktitle = {{{JCTVC}}-{{L1100}}},
  author = {Bossen, Frank and others},
  year = {2013},
  volume = {12},
  annotation = {HEVCé€šç”¨æµ‹è¯•é…ç½®}
}

@inproceedings{HEVCExSCCTestConditions,
  title = {Common Test Conditions and Software Reference Configurations for {{HEVC}} Range Extensions},
  booktitle = {{{JCT}}-{{VC P1006}}, 16th {{Meeting}} of {{JCT}}-{{VC}}},
  author = {Rosewarne, C and Sharman, K and Flynn, D},
  year = {2014},
  pages = {1--10},
  annotation = {HEVCæ‰©å±•æ ‡å‡†æµ‹è¯•é…ç½®}
}

@misc{HEVCsoftwareHM16,
  title = {{{HEVC}} Reference Software {{HM}}-16},
  author = {Bossen, F},
  annotation = {HEVCå‚è€ƒè½¯ä»¶HM16}
}

@misc{JPEGStandardITU,
  title = {T.81~:~Information Technology - Digital Compression and Coding of Continuous-Tone Still Images - Requirements and Guidelines},
  annotation = {JPEG ITU æ ‡å‡†},
  howpublished = {https://www.itu.int/rec/T-REC-T.81-199209-I/en}
}

@inproceedings{LatestLosslessIntraCodingAsRef,
  title = {A Fast Lossless Implementation of the Intra Subpartition Mode for {{VVC}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {{De-Lux{\'a}n-Hern{\'a}ndez}, S. and Venugopal, G. and George, V. and Schwarz, H. and Marpe, D. and Wiegand, T.},
  year = {2020},
  month = oct,
  pages = {1118--1122},
  issn = {2381-8549},
  doi = {10.1109/ICIP40778.2020.9191103},
  abstract = {Lossy compression is the main target of the upcoming video coding standard Versatile Video Coding (VVC). However, lossless coding is supported in VVC by utilizing a certain encoder configuration. Particularly, the Transform Skip Mode (TSM) is always selected at the block level to bypass the transform stage (together with a QP that results in the same output as input at the quantization stage). Consequently, the Intra Subpartition (ISP) coding mode cannot be used for lossless coding, considering that its combination with TSM is not supported in VVC because it does not provide a significant coding benefit for the lossy common test conditions. For this reason, it is proposed to enable such a combination for the benefit of lossless coding. Besides, the encoder search has been optimized to improve the trade-off between compression benefit and encoder run-time. Experimental results show a 0.71\% coding gain with a corresponding encoder run-time of 111\%.},
  annotation = {æœ€æ–°çš„æ— æŸåº”ç”¨ï¼Œåšå‚è€ƒæ–‡çŒ®},
  file = {E\:\\Documents\\Zotero\\storage\\56LRRNEL\\2020 - A Fast Lossless Implementation Of The Intra Subpartition Mode For VVC - De-LuxÃ¡n-HernÃ¡ndez ç­‰ã€‚.pdf},
  keywords = {coding gain,Copper,data compression,Decoding,Encoding,Estimation,fast encoder search,fast lossless implementation,intra prediction,Intra Subpartition coding mode,Intra Subpartition Mode,intra subpartitions,ISP,lossless coding,lossy common test conditions,lossy compression,rate distortion theory,significant coding benefit,standard Versatile Video Coding,Tools,Transform Skip Mode,transform stage,Transforms,TSM,upcoming video,video coding,Video coding,VVC}
}

@phdthesis{LineCodeDocPaper,
  title = {{åŸºäºè¡Œç»“æ„çš„å›¾åƒç¼–ç }},
  author = {å½­, ç§€è²},
  year = {2012},
  abstract = {éšç€æ•°å­—å›¾åƒåœ¨å¤šåª’ä½“ä¸­çš„å¹¿æ³›åº”ç”¨ã€å›¾åƒåˆ†è¾¨ç‡çš„ä¸æ–­å¢åŠ ä»¥åŠæ–°çš„å›¾åƒè¡¨ç¤ºå½¢å¼çš„è¯ç”Ÿ,å›¾åƒç¼–ç æ— è®ºåœ¨ç¼–ç æ€§èƒ½è¿˜æ˜¯è®¡ç®—ã€å­˜å‚¨å¤æ‚åº¦ä¸Šéƒ½é¢ä¸´ç€æ–°çš„æŒ‘æˆ˜ã€‚ç°ä»Šä¸»æµçš„å›¾åƒå’Œå¸§å†…ç¼–ç æŠ€æœ¯éƒ½é‡‡ç”¨äº†åŸºäºå—ç»“æ„çš„ç¼–ç ,å…¶ä¸­æœ€å…ˆè¿›çš„ç¼–ç æ ‡å‡†H.264/AVCåœ¨å¸§å†…ç¼–ç æ—¶é‡‡ç”¨äº†å—ç»“æ„é¢„æµ‹å’ŒäºŒç»´å˜æ¢çš„æ–¹æ³•ã€‚ç„¶è€Œ,å—å—ç»“æ„çš„é™åˆ¶,å…¶é¢„æµ‹çš„æ€§èƒ½å¹¶ä¸å¥½,ä»è€Œå½±å“äº†å—ç»“æ„ç¼–ç çš„æ€§èƒ½ã€‚å¦ä¸€æ–¹é¢,å—ç»“æ„çš„ç¼–ç ä¸ºäº†æ¶ˆé™¤å—é—´çš„ç›¸å…³æ€§å¼•å…¥äº†è¾ƒå¼ºçš„å—é—´ç¼–ç ä¾èµ–æ€§,ä½¿å¾—å®ƒä¸é€‚äºé«˜å¹¶è¡Œåº¦çš„ç¼–ç æ¥æé«˜ç¼–ç é€Ÿåº¦,è€Œå—ç»“æ„çš„ç¼–ç ä»å­˜å‚¨å¤æ‚åº¦ä¸Šæ¥è¯´ä¹Ÿä¸æ˜¯æœ€ä¼˜çš„é€‰æ‹©ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜,æœ¬æ–‡ä»æ”¹å˜ç¼–ç ç»“æ„çš„è§’åº¦å…¥æ‰‹,æå‡ºäº†åŸºäºè¡Œç»“æ„çš„ç¼–ç ã€‚ 	æœ¬æ–‡é¦–å…ˆ...},
  annotation = {è¡Œç¼–ç  ä¸­ç§‘å¤§åšå£«è®ºæ–‡},
  file = {E\:\\Documents\\Zotero\\storage\\Z46VVE7U\\å½­ - 2012 - åŸºäºè¡Œç»“æ„çš„å›¾åƒç¼–ç .caj},
  keywords = {block-based coding,broadcast,distributed source coding,H.264/AVC,image coding,parallel coding,prediction,transform,åˆ†å¸ƒå¼ç¼–ç ,å˜æ¢H.264/AVCå—ç»“æ„çš„ç¼–ç ,å›¾åƒç¼–ç ,å¹¶è¡Œç¼–ç ,å¹¿æ’­ä¼ è¾“,é¢„æµ‹},
  language = {ä¸­æ–‡;},
  school = {ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦},
  type = {{åšå£«}}
}

@article{LineCodeSaveMemoryEnergyEfficient,
  title = {An Energy-Efficient Low-Memory Image Compression System for Multimedia {{IoT}} Products},
  author = {Lee, Seong-Won and Kim, Ho-Young},
  year = {2018},
  month = dec,
  volume = {2018},
  pages = {87},
  issn = {1687-5281},
  doi = {10.1186/s13640-018-0333-3},
  abstract = {Emerging Internet of things (IoT) technologies have rapidly expanded to multimedia applications, including highresolution image transmission. However, handling image data in IoT products with limited battery capacity requires low-complexity and small-size solutions such as low-memory compression techniques. The objective of this paper is to propose a line-based compression system based on four-level two-line discrete wavelet transform and adaptive line prediction. Bit stream is generated by multiplexing various frequency components with run-level coding combined with Huffman coding. The proposed system also includes a new bit rate control algorithm that could significantly improve image quality consistency in one frame. The proposed low-memory compression system can retain image quality for visually lossless compression criteria over the whole image frame. It can simultaneously lower total system power consumption in multimedia IoT products better than other existing low-memory compression techniques.},
  annotation = {è¡Œç¼–ç  èŠ‚çœå­˜å‚¨ç©ºé—´},
  file = {E\:\\Documents\\Zotero\\storage\\N4GL59SF\\Lee å’Œ Kim - 2018 - An energy-efficient low-memory image compression s.pdf},
  journal = {EURASIP Journal on Image and Video Processing},
  language = {en},
  number = {1}
}

@article{LOCOi,
  title = {The {{LOCO}}-i Lossless Image Compression Algorithm: Principles and Standardization into {{JPEG}}-{{LS}}},
  shorttitle = {The {{LOCO}}-i Lossless Image Compression Algorithm},
  author = {Weinberger, M. J. and Seroussi, G. and Sapiro, G.},
  year = {2000},
  month = aug,
  volume = {9},
  pages = {1309--1324},
  issn = {1941-0042},
  doi = {10.1109/83.855427},
  abstract = {LOCO-I (LOw COmplexity LOssless COmpression for Images) is the algorithm at the core of the new ISO/ITU standard for lossless and near-lossless compression of continuous-tone images, JPEG-LS. It is conceived as a "low complexity projection" of the universal context modeling paradigm, matching its modeling unit to a simple coding unit. By combining simplicity with the compression potential of context models, the algorithm "enjoys the best of both worlds." It is based on a simple fixed context model, which approaches the capability of the more complex universal techniques for capturing high-order dependencies. The model is tuned for efficient performance in conjunction with an extended family of Golomb (1966) type codes, which are adaptively chosen, and an embedded alphabet extension for coding of low-entropy image regions. LOCO-I attains compression ratios similar or superior to those obtained with state-of-the-art schemes based on arithmetic coding. Moreover, it is within a few percentage points of the best available compression ratios, at a much lower complexity level. We discuss the principles underlying the design of LOCO-I, and its standardization into JPEC-LS.},
  annotation = {æ–°Planaræ¥æºLOCO-i},
  file = {E\:\\Documents\\Zotero\\storage\\Y9L3FUA9\\2000 - The LOCO-I lossless image compression algorithm principles and standardization into JPEG-LS - Weinberger ç­‰ã€‚.pdf},
  journal = {IEEE Transactions on Image Processing},
  keywords = {Arithmetic,arithmetic codes,arithmetic coding,code standards,coding unit,compression ratios,computational complexity,Context modeling,continuous-tone images,data compression,Data compression,Decoding,efficient performance,embedded alphabet extension,entropy,fixed context model,Golomb-type codes,high-order dependencies,image coding,Image coding,Inference algorithms,ISO standards,ISO/ITU standard,JPEG-LS,Laboratories,LOGO-I lossless image compression algorithm,lossless compression,low complexity lossless compression for images,low complexity projection,low-entropy image regions,modeling unit,near-lossless compression,Solid modeling,standardisation,standardization,Standardization,universal context modeling paradigm},
  number = {8}
}

@article{pwmResidualsPiecewiseMapping,
  title = {Piecewise Mapping in {{HEVC}} Lossless Intra-Prediction Coding},
  author = {Sanchez, Victor and {Aul{\'i}-Llin{\`a}s}, Francesc and {Serra-Sagrist{\`a}}, Joan},
  year = {2016},
  month = sep,
  volume = {25},
  pages = {4004--4017},
  issn = {1941-0042},
  doi = {10.1109/TIP.2016.2571065},
  abstract = {The lossless intra-prediction coding modality of the High Efficiency Video Coding standard provides high coding performance while allowing frame-by-frame basis access to the coded data. This is of interest in many professional applications, such as medical imaging, automotive vision, and digital preservation in libraries and archives. Various improvements to lossless intra-prediction coding have been proposed recently, most of them based on sample-wise prediction using differential pulse code modulation (DPCM). Other recent proposals aim at further reducing the energy of intra-predicted residual blocks. However, the energy reduction achieved is frequently minimal due to the difficulty of correctly predicting the sign and magnitude of residual values. In this paper, we pursue a novel approach to this energy-reduction problem using piecewise mapping (pwm) functions. In particular, we analyze the range of values in residual blocks and apply accordingly a pwm function to map specific residual values to unique lower values. We encode the appropriate parameters associated with the pwm functions at the encoder, so that the corresponding inverse pwm functions at the decoder can map values back to the same residual values. These residual values are then used to reconstruct the original signal. This mapping is, therefore, reversible and introduces no losses. We evaluate the pwm functions on 4 \texttimes{} 4 residual blocks computed after DPCM-based prediction for lossless coding of a variety of camera-captured and screen content sequences. Evaluation results show that the pwm functions can attain the maximum bitrate reductions of 5.54\% and 28.33\% for screen content material compared with DPCM-based and block-wise intra-prediction, respectively. Compared with intra-block copy, piecewise mapping can attain the maximum bit-rate reductions of 11.48\% for a camera-captured material.},
  annotation = {æ®‹å·®åˆ†æ®µæ˜ å°„},
  file = {E\:\\Documents\\Zotero\\storage\\EGC5R5TW\\2016 - Piecewise Mapping in HEVC Lossless Intra-Prediction Coding - Sanchez ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\X7VTMNL5\\7473932.html},
  journal = {IEEE Transactions on Image Processing},
  keywords = {Biomedical imaging,coded data,differential pulse code modulation,DPCM,Encoding,HEVC intra-prediction,HEVC lossless intraprediction coding,high efficiency video coding,Image coding,Image edge detection,intrapredicted residual blocks,lossless coding,piecewise mapping,piecewise mapping functions,pulse code modulation,Pulse width modulation,PWM functions,sample wise prediction,SAP,screen content sequences,Transforms,video coding},
  number = {9}
}

@inproceedings{SAP-SAP1,
  title = {Improvements to {{HEVC}} Intra Coding for Lossless Medical Image Compression},
  booktitle = {2014 {{Data Compression Conference}}},
  author = {Sanchez, V. and Llin{\`a}s, F. A. and Rapesta, J. B. and Sagrist{\`a}, J. S.},
  year = {2014},
  month = mar,
  pages = {423--423},
  issn = {2375-0359},
  doi = {10.1109/DCC.2014.76},
  abstract = {This works focuses on the High Efficiency Video Coding (HEVC) standard as a compression method to be potentially adopted by the Digital Imaging and Communications in Medicine (DICOM) standard. We are particularly interested in improving the lossless compression efficiency of the intra coding process for grayscale anatomical medical images. We focus on intra coding due to its low complexity and outstanding compression results, as well as the fact that it allows coding high-dimensional medical images on a slice-by-slice basis. This is especially advantageous for cases when only a small set of slices needs to be accessed without the need to decode the entire data set. Based on the characteristics of grayscale anatomical medical images, specifically their large amount of edge information and frequent number of patterns depicted on various directions, we propose improvements to HEVC intra coding based on sample-by-sample (SbS) differential pulse code modulation (DPCM) with equal displacements so the density of prediction modes is constant in all directions. Performance evaluations over MRI, CT and X-ray angiography sequences show that the proposed improvements outperform current HEVC lossless intra coding, achieving average coding gains of 6\%.},
  annotation = {SAPç³»åˆ—SAP-SAP1},
  file = {E\:\\Documents\\Zotero\\storage\\IU2E9ZJN\\2014 - Improvements to HEVC intra coding for lossless medical image compression - Sanchez ç­‰ã€‚.pdf},
  keywords = {data compression,Data compression,DICOM,DICOM standard,Digital Imaging and Communications in Medicine standard,DPCM,Encoding,Gray-scale,grayscale anatomical medical images,HEVC intracoding,high efficiency video coding standard,high-dimensional medical image coding,Image coding,lossless compression efficiency,lossless medical image compression,medical image processing,sample-by-sample differential pulse code modulation,SbS,Standards,video coding}
}

@article{StillImageIntraCompressRatioAllTest,
  title = {{{OVERVIEW AND BENCHMARKING SUMMARY FOR THE ICIP}} 2016 {{COMPRESSION CHALLENGE}}},
  author = {Alexiou, Evangelos and Viola, Irene and Krasula, Lukas and Richter, Thomas and Bruylants, Tim and Pinheiro, Antonio and Fliegel, Karel and Rerabek, Martin and Skodras, Athanassios and Schelkens, Peter and Ebrahimi, Touradj},
  year = {2016},
  pages = {38},
  annotation = {é™æ€ å¸§å†… å„ç§ç®—æ³•å‹ç¼©ç‡ç»Ÿè®¡},
  file = {E\:\\Documents\\Zotero\\storage\\RBELLSP6\\Alexiou ç­‰ã€‚ - 2016 - OVERVIEW AND BENCHMARKING SUMMARY FOR THE ICIP 201.pdf},
  language = {en}
}

@inproceedings{VVCComplexityAnalysisEncodeTime30xDecodeTime3x,
  title = {Complexity {{Analysis Of Next}}-{{Generation VVC Encoding And Decoding}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {Pakdaman, F. and Adelimanesh, M. A. and Gabbouj, M. and Hashemi, M. R.},
  year = {2020},
  month = oct,
  pages = {3134--3138},
  issn = {2381-8549},
  doi = {10.1109/ICIP40778.2020.9190983},
  abstract = {While the next generation video compression standard, Versatile Video Coding (VVC), provides a superior compression efficiency, its computational complexity dramatically increases. This paper thoroughly analyzes this complexity for both encoder and decoder of VVC Test Model 6, by quantifying the complexity break-down for each coding tool and measuring the complexity and memory requirements for VVC encoding/decoding. These extensive analyses are performed for six video sequences of 720p, 1080p, and 2160p, under Low-Delay (LD), Random-Access (RA), and All-Intra (AI) conditions (a total of 320 encoding/decoding). Results indicate that the VVC encoder and decoder are 5\texttimes{} and 1.5\texttimes{} more complex compared to HEVC in LD, and 31\texttimes{} and 1.8\texttimes{} in AI, respectively. Detailed analysis of coding tools reveals that in LD on average, motion estimation tools with 53\%, transformation and quantization with 22\%, and entropy coding with 7\% dominate the encoding complexity. In decoding, loop filters with 30\%, motion compensation with 20\%, and entropy decoding with 16\%, are the most complex modules. Moreover, the required memory bandwidth for VVC encoding/decoding are measured through memory profiling, which are 30\texttimes{} and 3\texttimes{} of HEVC. The reported results and insights are a guide for future research and implementations of energy-efficient VVC encoder/decoder.},
  annotation = {VVC å¤æ‚åº¦åˆ†æ ç¼–ç  30x è§£ç  3x},
  file = {E\:\\Documents\\Zotero\\storage\\ZSKQCQF5\\2020 - Complexity Analysis Of Next-Generation VVC Encoding And Decoding - Pakdaman ç­‰ã€‚.pdf},
  keywords = {complexity analysis,Conferences,Data compression,IEC Standards,Image processing,Indexes,ISO Standards,Tools,Versatile Video Coding (VVC),video coding,video decoding,VVC Test Model (VTM)}
}

@inproceedings{VVCCompressRatio40PercentTime15x,
  title = {Rate-Distortion and Complexity Comparison of {{HEVC}} and {{VVC}} Video Encoders},
  booktitle = {2020 {{IEEE}} 11th {{Latin American Symposium}} on {{Circuits}} \& {{Systems}} ({{LASCAS}})},
  author = {Siqueira, Icaro and Correa, Guilherme and Grellert, Mateus},
  year = {2020},
  month = feb,
  pages = {1--4},
  publisher = {{IEEE}},
  address = {{San Jose, Costa Rica}},
  doi = {10.1109/LASCAS45839.2020.9069036},
  abstract = {Video-coding systems have presented significant improvements driven by the wide adoption of video streaming technologies combined with demands for better quality from users. The most recent video-coding standard from JCT-VC, named High Efficiency Video Coding, greatly improved the compression rate compared to its predecessor, H.264/AVC, but an even better performance must be pursued to accommodate future technologies. This article presents a comparison between the current state-of-art HEVC standard with the most recent project that is being conducted by the same group of experts, entitled Versatile Video Coding (VVC). According to experimental results obtained using similar configurations for both encoders, the VVC reference software provides significant bit-rate savings of 44.4\% on average when compared to HEVC. However, this compression gains come with high computational costs: the VVC encoding time is on average 10.2 times higher when SIMD are used, and 15.9 times higher without such optimizations.},
  annotation = {VVC å‹ç¼©ç‡ä¼˜åŒ– 40 percent æ—¶é—´ 15x},
  file = {E\:\\Documents\\Zotero\\storage\\3FJ9AMHU\\2020 - Rate-Distortion and Complexity Comparison of HEVC and VVC Video Encoders - Siqueira ç­‰ã€‚.pdf},
  isbn = {978-1-72813-427-7},
  language = {en}
}

@article{VVCCompressRatioTest30Percent,
  title = {Comparing {{VVC}}, {{HEVC}} and {{AV1}} Using Objective and Subjective Assessments},
  author = {Zhang, Fan and Katsenou, Angeliki V. and Afonso, Mariana and Dimitrov, Goce and Bull, David R.},
  year = {2020},
  month = mar,
  abstract = {In this paper, the performance of three state-ofthe-art video codecs: High Efficiency Video Coding (HEVC) Test Model (HM), AOMedia Video 1 (AV1) and Versatile Video Coding Test Model (VTM), are evaluated using both objective and subjective quality assessments. Nine source sequences were carefully selected to offer both diversity and representativeness, and different resolution versions were encoded by all three codecs at pre-defined target bitrates. The compression efficiency of the three codecs are evaluated using two commonly used objective quality metrics, PSNR and VMAF. The subjective quality of their reconstructed content is also evaluated through psychophysical experiments. Furthermore, HEVC and AV1 are compared within a dynamic optimization framework (convex hull rate-distortion optimization) across resolutions with a wider bitrate, using both objective and subjective evaluations. Finally the computational complexities of three tested codecs are compared. The subjective assessments indicate that, for the tested versions there is no significant difference between AV1 and HM, while the tested VTM version shows significant enhancements. The selected source sequences, compressed video content and associated subjective data are available online, offering a resource for compression performance evaluation and objective video quality assessment.},
  annotation = {VVCå‹ç¼©ç‡æµ‹è¯•30Percent},
  archiveprefix = {arXiv},
  eprint = {2003.10282},
  eprinttype = {arxiv},
  file = {E\:\\Documents\\Zotero\\storage\\XLPBV5A5\\2020 - Comparing VVC, HEVC and AV1 using Objective and Subjective Assessments - Zhang ç­‰ã€‚.pdf},
  journal = {arXiv:2003.10282 [eess]},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
  language = {en},
  primaryclass = {eess}
}

@inproceedings{VVCTestConditions,
  title = {{{JVET}} Common Test Conditions and Software Reference Configurations},
  shorttitle = {{{JVET}}-{{J1010}}},
  author = {Boyce, Jill and Suehring, Karsten and Li, Xiang and Seregin, Vadim},
  year = {2018},
  month = jul,
  abstract = {This document defines common test conditions and software reference configurations to be used in the context of core experiments (CE) conducted after the 10 th JVET meeting. These common test conditions are also recommended for use in technical contributions to the 11 th and following JVET meetings, if applicable.},
  annotation = {VVCæµ‹è¯•é…ç½®},
  file = {E\:\\Documents\\Zotero\\storage\\J42CZN8R\\2018 - JVET-J1010 JVET common test conditions and software reference configurations - Boyce ç­‰ã€‚.pdf}
}

@article{XiDianIntraPredictionH264,
  title = {ä¸€ç§é™ä½é¢„æµ‹æ¨¡å¼å¼€é”€çš„å¸§å†…é¢„æµ‹æ–¹æ³•},
  author = {{å…ƒè¾‰;å¸¸ä¹‰æ—;å¢æœé˜³;ææ˜}},
  year = {2010},
  volume = {37},
  pages = {981},
  publisher = {{è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦å­¦æŠ¥}},
  doi = {10.3969/j.issn.1001-2400.2010.06.001},
  abstract = {æå‡ºä¸€ç§æ–°é¢–çš„å¸§å†…é¢„æµ‹æ–¹æ³•ï¼æ¯”è¾ƒæ¯ç§é¢„æµ‹æ¨¡å¼çš„é¢„æµ‹å—ä¸ç›´æµ(DC)é¢„æµ‹æ¨¡å¼çš„é¢„æµ‹å—ä¹‹é—´çš„ç»å¯¹å·®å’Œï¼è¿›è€Œåˆ¤æ–­å½“å‰å—åœ¨å„ç§é¢„æµ‹æ¨¡å¼ä¸‹çš„é¢„æµ‹å—æ˜¯å¦ç›¸ä¼¼ï¼è‹¥å½“å‰å—çš„å„ç§é¢„æµ‹å—éƒ½ç›¸ä¼¼ï¼Œåˆ™å°†æ‰€æœ‰é¢„æµ‹å—çš„å‡å€¼ä½œä¸ºå½“å‰å—çš„æœ€ç»ˆé¢„æµ‹ç»“æœï¼Œä¸”ä¸å¿…ç¼–ç é¢„æµ‹æ¨¡å¼ï¼å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•è¾ƒH.264/AVCèƒ½å¤Ÿè·å¾—æ›´é«˜çš„ç¼–ç æ€§èƒ½ï¼Œåœ¨æ¢å¤è§†é¢‘å®¢è§‚è´¨é‡PSNRç›¸åŒæ—¶ï¼Œç ç‡å¹³å‡ä¸‹é™2.40ï¼…ï¼Œç¼–ç æ—¶é—´å¹³å‡å‡å°‘25.83ï¼…ï¼},
  annotation = {è¥¿ç”µï¼Œä¸éœ€è¦ç¼–ç æ¨¡å¼ä¿¡æ¯çš„å¸§å†…é¢„æµ‹æ–¹å¼},
  eid = {981},
  journal = {è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦å­¦æŠ¥},
  keywords = {Â¡pÂ¿å¸§å†…é¢„æµ‹,H.264/AVC,æ¨¡å¼ä¿¡æ¯,è§†é¢‘ç¼–ç Â¡/pÂ¿},
  number = {6}
}


