
@article{待编码系数 扫描 二值化 哥伦布 莱斯,
  title = {Transform {{Coefficient Coding}} in {{HEVC}}},
  author = {Sole, J. and Joshi, R. and Nguyen, N. and Ji, T. and Karczewicz, M. and Clare, G. and Henry, F. and Duenas, A.},
  date = {2012-12},
  journaltitle = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {22},
  pages = {1765--1777},
  issn = {1558-2205},
  doi = {10.1109/TCSVT.2012.2223055},
  abstract = {This paper describes transform coefficient coding in the draft international standard of High Efficiency Video Coding (HEVC) specification and the driving motivations behind its design. Transform coefficient coding in HEVC encompasses the scanning patterns and coding methods for the last significant coefficient, significance map, coefficient levels, and sign data. Special attention is paid to the new methods of last significant coefficient coding, multilevel significance maps, high-throughput binarization, and sign data hiding. Experimental results are provided to evaluate the performance of transform coefficient coding in HEVC.},
  eventtitle = {{{IEEE Transactions}} on {{Circuits}} and {{Systems}} for {{Video Technology}}},
  file = {E\:\\Documents\\Zotero\\storage\\FGGUIEBA\\2012 - Transform Coefficient Coding in HEVC - Sole 等。.pdf;E\:\\Documents\\Zotero\\storage\\REQEIKL2\\6324418.html},
  keywords = {coefficient levels,data encapsulation,draft international standard,Encoding,HEVC specification,high efficiency video coding,High Efficiency Video Coding (HEVC),high throughput entropy coder,high-throughput binarization,last significant coefficient coding,multilevel significance maps,scanning patterns,sign data hiding,Throughput,transform coding,transform coefficient coding,Transforms,video coding,Video coding},
  number = {12}
}

@article{静态 帧内 各种算法压缩率统计,
  title = {{{OVERVIEW AND BENCHMARKING SUMMARY FOR THE ICIP}} 2016 {{COMPRESSION CHALLENGE}}},
  author = {Alexiou, Evangelos and Viola, Irene and Krasula, Lukas and Richter, Thomas and Bruylants, Tim and Pinheiro, Antonio and Fliegel, Karel and Rerabek, Martin and Skodras, Athanassios and Schelkens, Peter and Ebrahimi, Touradj},
  date = {2016},
  pages = {38},
  file = {E\:\\Documents\\Zotero\\storage\\RBELLSP6\\Alexiou 等。 - 2016 - OVERVIEW AND BENCHMARKING SUMMARY FOR THE ICIP 201.pdf},
  langid = {english}
}

@article{行编码 节省存储空间,
  title = {An Energy-Efficient Low-Memory Image Compression System for Multimedia {{IoT}} Products},
  author = {Lee, Seong-Won and Kim, Ho-Young},
  date = {2018-12},
  journaltitle = {EURASIP Journal on Image and Video Processing},
  shortjournal = {J Image Video Proc.},
  volume = {2018},
  pages = {87},
  issn = {1687-5281},
  doi = {10.1186/s13640-018-0333-3},
  url = {https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-018-0333-3},
  urldate = {2020-02-22},
  abstract = {Emerging Internet of things (IoT) technologies have rapidly expanded to multimedia applications, including highresolution image transmission. However, handling image data in IoT products with limited battery capacity requires low-complexity and small-size solutions such as low-memory compression techniques. The objective of this paper is to propose a line-based compression system based on four-level two-line discrete wavelet transform and adaptive line prediction. Bit stream is generated by multiplexing various frequency components with run-level coding combined with Huffman coding. The proposed system also includes a new bit rate control algorithm that could significantly improve image quality consistency in one frame. The proposed low-memory compression system can retain image quality for visually lossless compression criteria over the whole image frame. It can simultaneously lower total system power consumption in multimedia IoT products better than other existing low-memory compression techniques.},
  file = {E\:\\Documents\\Zotero\\storage\\N4GL59SF\\Lee 和 Kim - 2018 - An energy-efficient low-memory image compression s.pdf},
  langid = {english},
  number = {1}
}

@thesis{行编码 中科大博士论文,
  title = {基于行结构的图像编码},
  author = {彭, 秀莲},
  date = {2012},
  institution = {{中国科学技术大学}},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&dbname=CDFD1214&filename=1012503624.nh&uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0s4bm54TUN3cTJGYWptMHZNTVZKTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!&v=MzEzMjRITGE0SGRmT3E1RWJQSVI4ZVgxTHV4WVM3RGgxVDNxVHJXTTFGckNVUkxPZVplZHNGeWpsVXJyTFZGMjY=},
  urldate = {2019-12-13},
  abstract = {随着数字图像在多媒体中的广泛应用、图像分辨率的不断增加以及新的图像表示形式的诞生,图像编码无论在编码性能还是计算、存储复杂度上都面临着新的挑战。现今主流的图像和帧内编码技术都采用了基于块结构的编码,其中最先进的编码标准H.264/AVC在帧内编码时采用了块结构预测和二维变换的方法。然而,受块结构的限制,其预测的性能并不好,从而影响了块结构编码的性能。另一方面,块结构的编码为了消除块间的相关性引入了较强的块间编码依赖性,使得它不适于高并行度的编码来提高编码速度,而块结构的编码从存储复杂度上来说也不是最优的选择。针对这些问题,本文从改变编码结构的角度入手,提出了基于行结构的编码。 	本文首先...},
  file = {E\:\\Documents\\Zotero\\storage\\Z46VVE7U\\彭 - 2012 - 基于行结构的图像编码.caj},
  keywords = {block-based coding,broadcast,distributed source coding,H.264/AVC,image coding,parallel coding,prediction,transform,分布式编码,变换H.264/AVC块结构的编码,图像编码,并行编码,广播传输,预测},
  langid = {中文;},
  type = {博士}
}

@inproceedings{遗传算法 数值编码压缩,
  title = {Image Compression Based on Genetic Algorithm Optimization},
  booktitle = {2015 2nd {{World Symposium}} on {{Web Applications}} and {{Networking}} ({{WSWAN}})},
  author = {Omari, Mohammed and Yaichi, Salah},
  date = {2015-03},
  pages = {1--5},
  doi = {10.1109/WSWAN.2015.7210304},
  abstract = {Image compression has attracted a lot of research since the beginning of Internet era and telecommunication. Enhancing image compression quality and ratio was achieved through several approaches such as neural networks and discrete transforms. However, other heuristic and bio-inspired methods such as genetic algorithms are still under experimentation. In this paper, we introduced a new image compression mechanism based on exploiting the relationship between fractional numbers and their corresponding quotient representation. Each sub-image is mapped to a fractional number based on the RGB representation, and then reduced to an efficient quotient. The appeal of using genetic algorithms is explained by the massive search to find a close fraction that is reduced to short quotient. Our method showed a considerable compression ratio when the least significant bits of each byte are altered, hence, the image quality is preserved while achieving high compression ratio.},
  eventtitle = {2015 2nd {{World Symposium}} on {{Web Applications}} and {{Networking}} ({{WSWAN}})},
  file = {E\:\\Documents\\Zotero\\storage\\U96UTKKM\\Omari 和 Yaichi - 2015 - Image compression based on genetic algorithm optim.pdf;E\:\\Documents\\Zotero\\storage\\FLZGVK5X\\7210304.html},
  keywords = {Biological cells,data compression,Fractal image,fractional numbers,genetic algorithm optimization,genetic algorithms,Genetic algorithms,image coding,Image coding,image colour analysis,image compression quality enhancement,image compression ratio enhancement,image representation,Internet era,least significant bits,lossy compression,number theory,quotient representation,rational numbers,RGB representation,Sociology,Statistics,telecommunication,Wavelet transforms}
}

@article{DCT 系数 数学分析,
  title = {A Mathematical Analysis of the {{DCT}} Coefficient Distributions for Images},
  author = {Lam, E. Y. and Goodman, J. W.},
  date = {2000-10},
  journaltitle = {IEEE Transactions on Image Processing},
  volume = {9},
  pages = {1661--1666},
  issn = {1941-0042},
  doi = {10.1109/83.869177},
  abstract = {Over the past two decades, there have been various studies on the distributions of the DCT coefficients for images. However, they have concentrated only on fitting the empirical data from some standard pictures with a variety of well-known statistical distributions, and then comparing their goodness of fit. The Laplacian distribution is the dominant choice balancing simplicity of the model and fidelity to the empirical data. Yet, to the best of our knowledge, there has been no mathematical justification as to what gives rise to this distribution. We offer a rigorous mathematical analysis using a doubly stochastic model of the images, which not only provides the theoretical explanations necessary, but also leads to insights about various other observations from the literature. This model also allows us to investigate how certain changes in the image statistics could affect the DCT coefficient distributions.},
  eventtitle = {{{IEEE Transactions}} on {{Image Processing}}},
  file = {E\:\\Documents\\Zotero\\storage\\7JSMWCYC\\2000 - A mathematical analysis of the DCT coefficient distributions for images - Lam 和 Goodman.pdf},
  keywords = {central limit theorem,DCT coefficient distributions,discrete cosine transforms,Discrete cosine transforms,doubly stochastic model,empirical data,Gaussian distribution,Histograms,image coding,Image coding,image statistics,Laplace equations,Laplacian distribution,mathematical analysis,Mathematical analysis,Mathematical model,standard pictures,statistical distributions,Statistical distributions,stochastic processes,Stochastic processes,Testing,transform coding},
  number = {10}
}

@online{JPEG ITU 标准,
  title = {T.81~:~{{Information}} Technology - {{Digital}} Compression and Coding of Continuous-Tone Still Images - {{Requirements}} and Guidelines},
  url = {https://www.itu.int/rec/T-REC-T.81-199209-I/en},
  urldate = {2021-03-24}
}

@software{latex 入门 教学 github repo,
  title = {Luong-Komorebi/{{Begin}}-{{Latex}}-in-Minutes},
  author = {Vo, Luong},
  date = {2021-03-22T16:17:15Z},
  origdate = {2016-10-30T11:01:23Z},
  url = {https://github.com/luong-komorebi/Begin-Latex-in-minutes},
  urldate = {2021-03-24},
  abstract = {📜 Brief Intro to LaTeX for beginners that helps you use LaTeX with ease.},
  keywords = {basic,beginners,fast,guide,latex,latex-editor,latex-in-minutes,simple}
}

@online{VVC 复杂度分析 编码 30x 解码 3x,
  title = {Complexity {{Analysis Of Next}}-{{Generation VVC Encoding And Decoding}}},
  url = {https://ieeexplore.ieee.org/document/9190983},
  urldate = {2021-03-04},
  abstract = {While the next generation video compression standard, Versatile Video Coding (VVC), provides a superior compression efficiency, its computational complexity dramatically increases. This paper thoroughly analyzes this complexity for both encoder and decoder of VVC Test Model 6, by quantifying the complexity break-down for each coding tool and measuring the complexity and memory requirements for VVC encoding/decoding. These extensive analyses are performed for six video sequences of 720p, 1080p, and 2160p, under Low-Delay (LD), Random-Access (RA), and All-Intra (AI) conditions (a total of 320 encoding/decoding). Results indicate that the VVC encoder and decoder are 5× and 1.5× more complex compared to HEVC in LD, and 31× and 1.8× in AI, respectively. Detailed analysis of coding tools reveals that in LD on average, motion estimation tools with 53\%, transformation and quantization with 22\%, and entropy coding with 7\% dominate the encoding complexity. In decoding, loop filters with 30\%, motion compensation with 20\%, and entropy decoding with 16\%, are the most complex modules. Moreover, the required memory bandwidth for VVC encoding/decoding are measured through memory profiling, which are 30× and 3× of HEVC. The reported results and insights are a guide for future research and implementations of energy-efficient VVC encoder/decoder.},
  file = {E\:\\Documents\\Zotero\\storage\\QFLIL2YL\\Complexity Analysis Of Next-Generation VVC Encoding And Decoding - .pdf},
  langid = {american}
}

@online{VVC 压缩率优化 30 percent,
  title = {Comparing {{VVC}}, {{HEVC}} and {{AV1}} Using {{Objective}} and {{Subjective Assessments}}},
  author = {Zhang, Fan and Katsenou, Angeliki V. and Afonso, Mariana and Dimitrov, Goce and Bull, David R.},
  date = {2020-03-23},
  url = {http://arxiv.org/abs/2003.10282},
  urldate = {2021-03-03},
  abstract = {In this paper, the performance of three state-ofthe-art video codecs: High Efficiency Video Coding (HEVC) Test Model (HM), AOMedia Video 1 (AV1) and Versatile Video Coding Test Model (VTM), are evaluated using both objective and subjective quality assessments. Nine source sequences were carefully selected to offer both diversity and representativeness, and different resolution versions were encoded by all three codecs at pre-defined target bitrates. The compression efficiency of the three codecs are evaluated using two commonly used objective quality metrics, PSNR and VMAF. The subjective quality of their reconstructed content is also evaluated through psychophysical experiments. Furthermore, HEVC and AV1 are compared within a dynamic optimization framework (convex hull rate-distortion optimization) across resolutions with a wider bitrate, using both objective and subjective evaluations. Finally the computational complexities of three tested codecs are compared. The subjective assessments indicate that, for the tested versions there is no significant difference between AV1 and HM, while the tested VTM version shows significant enhancements. The selected source sequences, compressed video content and associated subjective data are available online, offering a resource for compression performance evaluation and objective video quality assessment.},
  archiveprefix = {arXiv},
  eprint = {2003.10282},
  eprinttype = {arxiv},
  file = {E\:\\Documents\\Zotero\\storage\\XLPBV5A5\\2020 - Comparing VVC, HEVC and AV1 using Objective and Subjective Assessments - Zhang 等。.pdf},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
  langid = {english},
  primaryclass = {eess}
}

@inproceedings{VVC 压缩率优化 40 percent 时间 15x,
  title = {Rate-{{Distortion}} and {{Complexity Comparison}} of {{HEVC}} and {{VVC Video Encoders}}},
  booktitle = {2020 {{IEEE}} 11th {{Latin American Symposium}} on {{Circuits}} \& {{Systems}} ({{LASCAS}})},
  author = {Siqueira, Icaro and Correa, Guilherme and Grellert, Mateus},
  date = {2020-02},
  pages = {1--4},
  publisher = {{IEEE}},
  location = {{San Jose, Costa Rica}},
  doi = {10.1109/LASCAS45839.2020.9069036},
  url = {https://ieeexplore.ieee.org/document/9069036/},
  urldate = {2021-03-04},
  abstract = {Video-coding systems have presented significant improvements driven by the wide adoption of video streaming technologies combined with demands for better quality from users. The most recent video-coding standard from JCT-VC, named High Efficiency Video Coding, greatly improved the compression rate compared to its predecessor, H.264/AVC, but an even better performance must be pursued to accommodate future technologies. This article presents a comparison between the current state-of-art HEVC standard with the most recent project that is being conducted by the same group of experts, entitled Versatile Video Coding (VVC). According to experimental results obtained using similar configurations for both encoders, the VVC reference software provides significant bit-rate savings of 44.4\% on average when compared to HEVC. However, this compression gains come with high computational costs: the VVC encoding time is on average 10.2 times higher when SIMD are used, and 15.9 times higher without such optimizations.},
  eventtitle = {2020 {{IEEE}} 11th {{Latin American Symposium}} on {{Circuits}} \& {{Systems}} ({{LASCAS}})},
  file = {E\:\\Documents\\Zotero\\storage\\3FJ9AMHU\\2020 - Rate-Distortion and Complexity Comparison of HEVC and VVC Video Encoders - Siqueira 等。.pdf},
  isbn = {978-1-72813-427-7},
  langid = {english}
}


