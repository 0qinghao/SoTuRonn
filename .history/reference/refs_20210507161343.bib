
@article{1DTransformMotionResidual,
  title      = {1-d Transforms for the Motion Compensation Residual},
  author     = {Kamisli, Fatih and Lim, Jae S.},
  year       = {2011},
  month      = apr,
  volume     = {20},
  pages      = {1036--1046},
  issn       = {1941-0042},
  doi        = {10.1109/TIP.2010.2083675},
  abstract   = {Transforms used in image coding are also commonly used to compress prediction residuals in video coding. Prediction residuals have different spatial characteristics from images, and it is useful to develop transforms that are adapted to prediction residuals. In this paper, we explore the differences between the characteristics of images and motion compensated prediction residuals by analyzing their local anisotropic characteristics and develop transforms adapted to the local anisotropic characteristics of these residuals. The analysis indicates that many regions of motion compensated prediction residuals have 1-D anisotropic characteristics and we propose to use 1-D directional transforms for these regions. We present experimental results with one example set of such transforms within the H.264/AVC codec and the results indicate that the proposed transforms can improve the compression efficiency of motion compensated prediction residuals over conventional transforms.},
  annotation = {è¿åŠ¨æ®‹å·®å…·æœ‰æ²¿æŸæ–¹å‘çš„ç›¸å…³æ€§ ç”¨1D-DCT},
  file       = {E\:\\Documents\\Zotero\\storage\\ELI6JURD\\2011 - 1-D Transforms for the Motion Compensation Residual - Kamisli å’Œ Lim.pdf;E\:\\Documents\\Zotero\\storage\\TRVB35HQ\\5594636.html},
  journal    = {IEEE Transactions on Image Processing},
  keywords   = {1D directional transforms,Algorithms,Artifacts,compression efficiency,Correlation,discrete cosine transforms,Discrete cosine transforms,Discrete cosine transforms (DCTs),Discrete wavelet transforms,H.264/AVC codec,image coding,Image coding,Image edge detection,Image Enhancement,Image Interpretation; Computer-Assisted,Information Storage and Retrieval,local anisotropic characteristics,Mathematical model,Motion,motion compensation,motion compensation (MC),motion compensation residual,Pattern Recognition; Automated,prediction residuals,Reproducibility of Results,Sensitivity and Specificity,video coding,Video Recording},
  number     = {4},
  note       = {doi: 10.1109/TIP.2010.2083675}
}

@misc{AVCsoftwareJM,
  title      = {Bossen {{F}}, {{Sharman K}}, {{Suehring K}}, et al. {{H}}.264/{{AVC JM}} Reference Software [{{CP}}/{{OL}}]. [2021-04-23]. {{https://vcgit.hhi.fraunhofer.de/jvet/JM}}},
  abstract   = {H.264/AVC JM reference software},
  annotation = {AVCå‚è€ƒè½¯ä»¶JM}
}

@misc{BeginLatexGithubQuickStart,
  title      = {Luong-Komorebi/{{Begin}}-Latex-in-Minutes},
  author     = {Vo, Luong},
  year       = {2021},
  month      = mar,
  abstract   = {ğŸ“œ Brief Intro to LaTeX for beginners that helps you use LaTeX with ease.},
  annotation = {latex å…¥é—¨ æ•™å­¦ github repo},
  keywords   = {basic,beginners,fast,guide,latex,latex-editor,latex-in-minutes,simple}
}

@book{BookHEVCChinese,
  title      = {{æ–°ä¸€ä»£é«˜æ•ˆè§†é¢‘ç¼–ç H.265/HEVC}},
  author     = {{ä¸‡å¸…} and {æ¨ä»˜æ­£}},
  year       = {2014},
  publisher  = {{ç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾}},
  address    = {{åŒ—äº¬}},
  annotation = {HEVCä¸­æ–‡ä¹¦ OCLC: 917424983},
  file       = {E\:\\Documents\\Zotero\\storage\\RK9HRP9E\\æ–°ä¸€ä»£é«˜æ•ˆè§†é¢‘ç¼–ç H.265 HEVC  åŸç†ã€æ ‡å‡†ä¸å®ç°_ä¸‡å¸…ï¼Œæ¨ä»˜æ­£ç¼–è‘—_åŒ—äº¬ï¼šç”µå­å·¥ä¸šå‡ºç‰ˆç¤¾_2014.12_13661231_P387.pdf},
  isbn       = {978-7-121-24699-9},
  language   = {Chinese}
}

@book{BookHEVCEnglish,
  title      = {High {{Efficiency Video Coding}} ({{HEVC}}): {{Algorithms}} and {{Architectures}}},
  shorttitle = {High {{Efficiency Video Coding}} ({{HEVC}})},
  editor     = {Sze, Vivienne and Budagavi, Madhukar and Sullivan, Gary J.},
  year       = {2014},
  publisher  = {{Springer International Publishing}},
  address    = {{Cham}},
  doi        = {10.1007/978-3-319-06895-4},
  annotation = {HEVCè‹±æ–‡ä¹¦},
  file       = {E\:\\Documents\\Zotero\\storage\\9W4GANJZ\\2014 - High Efficiency Video Coding (HEVC) Algorithms and Architectures - Sze ç­‰ã€‚.pdf},
  isbn       = {978-3-319-06894-7 978-3-319-06895-4},
  series     = {Integrated {{Circuits}} and {{Systems}}},
  note       = {doi: 10.1007/978-3-319-06895-4}
}

@inproceedings{BypassImprovingSCC,
  title     = {Improving Screen Content Coding in {{HEVC}} by Transform Skipping},
  booktitle = {2012 {{Proceedings}} of the 20th {{European Signal Processing Conference}} ({{EUSIPCO}})},
  author    = {Mrak, M. and Xu, J.},
  year      = {2012},
  month     = aug,
  pages     = {1209--1213},
  issn      = {2076-1465},
  abstract  = {Screen content is nowadays a part of numerous applications - from desktop sharing to broadcasting. It consists of both camera captured content and computer generated content such as text and graphics. These two types of content have different properties requiring different processing and compression techniques. However, it is often required to compress such content with standard video coding solutions. In this paper a low-cost solution for improved screen content coding based on the upcoming video coding standard HEVC is presented. It includes specific intra and inter coding solutions that skip some of the common video coding methods, in this case transforms, enhancing the compression of screen content. Additional signalling and signal-level adjustment methods are introduced. Savings of up to 30\% of the bit-rate are observed for intra coding and up to 25\% for inter coding of screen content. Modest gains of up to 3\% are observed for content that consists of both camera captured content and graphics.},
  file      = {E\:\\Documents\\Zotero\\storage\\JGQRYJIN\\2012 - Improving screen content coding in HEVC by transform skipping - Mrak å’Œ Xu.pdf},
  keywords  = {bit-rate,camera captured content,Cameras,computer generated content,data compression,Encoding,error statistics,graphics,HEVC,high efficiency video coding,Image coding,intercoding,intracoding,quantisation,quantisation (signal),Quantization,screen content,screen content coding,screen content compression,signal-level adjustment method,signalling,spatial transforms,Standards,text,transform skipping,transforms,Transforms,video coding,Video coding,video coding standard}
}

@article{CoefficientScanBinGolombRice,
  title      = {Transform Coefficient Coding in {{HEVC}}},
  author     = {Sole, J. and Joshi, R. and Nguyen, N. and Ji, T. and Karczewicz, M. and Clare, G. and Henry, F. and Duenas, A.},
  year       = {2012},
  month      = dec,
  volume     = {22},
  pages      = {1765--1777},
  issn       = {1558-2205},
  doi        = {10.1109/TCSVT.2012.2223055},
  abstract   = {This paper describes transform coefficient coding in the draft international standard of High Efficiency Video Coding (HEVC) specification and the driving motivations behind its design. Transform coefficient coding in HEVC encompasses the scanning patterns and coding methods for the last significant coefficient, significance map, coefficient levels, and sign data. Special attention is paid to the new methods of last significant coefficient coding, multilevel significance maps, high-throughput binarization, and sign data hiding. Experimental results are provided to evaluate the performance of transform coefficient coding in HEVC.},
  annotation = {å¾…ç¼–ç ç³»æ•° äºŒå€¼åŒ– æ‰«æ å“¥ä¼¦å¸ƒ è±æ–¯},
  file       = {E\:\\Documents\\Zotero\\storage\\FGGUIEBA\\2012 - Transform Coefficient Coding in HEVC - Sole ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\REQEIKL2\\6324418.html},
  journal    = {IEEE Transactions on Circuits and Systems for Video Technology},
  keywords   = {coefficient levels,data encapsulation,draft international standard,Encoding,HEVC specification,high efficiency video coding,High Efficiency Video Coding (HEVC),high throughput entropy coder,high-throughput binarization,last significant coefficient coding,multilevel significance maps,scanning patterns,sign data hiding,Throughput,transform coding,transform coefficient coding,Transforms,video coding,Video coding},
  number     = {12},
  note       = {doi: 10.1109/TCSVT.2012.2223055}
}

@article{CrossComponentPredictionCCLM,
  title      = {Enhanced Cross-Component Linear Model for Chroma Intra-Prediction in Video Coding},
  author     = {Zhang, Kai and Chen, Jianle and Zhang, Li and Li, Xiang and Karczewicz, Marta},
  year       = {2018},
  month      = aug,
  volume     = {27},
  pages      = {3983--3997},
  issn       = {1941-0042},
  doi        = {10.1109/TIP.2018.2830640},
  abstract   = {Cross-component linear model (CCLM) for chroma intra-prediction is a promising coding tool in the joint exploration model (JEM) developed by the Joint Video Exploration Team (JVET). CCLM assumes a linear correlation between the luma and chroma components in a coding block. With this assumption, the chroma components can be predicted by the linear model (LM) mode, which utilizes the reconstructed neighboring samples to derive parameters of a linear model by linear regression. This paper presents three new methods to further improve the coding efficiency of CCLM. First, we introduce a multi-model CCLM (MM-CCLM) approach, which applies more than one linear model to a coding block. With MM-CCLM, reconstructed neighboring luma and chroma samples of the current block are classified into several groups, and a particular set of linear model parameters is derived for each group. The reconstructed luma samples of the current block are also classified to predict the associated chroma samples with the corresponding linear model. Second, we propose a multi-filter CCLM (MF-CCLM) technique, which allows the encoder to select the optimal down-sampling filter for the luma component with the 4:2:0 color format. Third, we present an LM-angular prediction method, which synthesizes the angular intra-prediction and the MM-CCLM intra-prediction into a new chroma intra-coding mode. Simulation results show that the BD-rate savings of 0.55\%, 4.66\%, and 5.08\% on average for Y, Cb, and Cr components, respectively, are achieved in all intra-configurations with the proposed three methods. MM-CCLM and MF-CCLM have been adopted into the JEM by JVET.},
  annotation = {äº®åº¦é¢„æµ‹è‰²å·® 3ä¸ªçº¿æ€§æ‹Ÿåˆæ¨¡å‹},
  file       = {E\:\\Documents\\Zotero\\storage\\PLI72HHI\\2018 - Enhanced Cross-Component Linear Model for Chroma Intra-Prediction in Video Coding - Zhang ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\NALNIH5K\\8350031.html},
  journal    = {IEEE Transactions on Image Processing},
  keywords   = {angular intraprediction,associated chroma samples,BD-rate savings,chroma components,chroma intra-prediction,chroma intracoding mode,chroma intraprediction,coding block,coding efficiency,coding tool,Correlation,Cr components,Cross-component linear model,current block,enhanced cross-component linear model,High efficiency video coding,image classification,Image coding,image colour analysis,image filtering,image reconstruction,Image reconstruction,intraconfigurations,JEM,joint exploration model,Joint Video Exploration Team,JVET,linear correlation,linear model mode,linear model parameters,linear regression,Linear regression,LM,LM-angular prediction method,luma component,MF-CCLM intraprediction,MM-CCLM,multi-filter,multi-model,multifilter CCLM,multimodel CCLM,optimal down-sampling filter,Predictive models,reconstructed luma samples,reconstructed neighboring samples,regression analysis,video coding,Video coding},
  number     = {8},
  note       = {doi: 10.1109/TIP.2018.2830640}
}

@article{DCTCoefficientMathAnalysis,
  title      = {A Mathematical Analysis of the {{DCT}} Coefficient Distributions for Images},
  author     = {Lam, E. Y. and Goodman, J. W.},
  year       = {2000},
  month      = oct,
  volume     = {9},
  pages      = {1661--1666},
  issn       = {1941-0042},
  doi        = {10.1109/83.869177},
  abstract   = {Over the past two decades, there have been various studies on the distributions of the DCT coefficients for images. However, they have concentrated only on fitting the empirical data from some standard pictures with a variety of well-known statistical distributions, and then comparing their goodness of fit. The Laplacian distribution is the dominant choice balancing simplicity of the model and fidelity to the empirical data. Yet, to the best of our knowledge, there has been no mathematical justification as to what gives rise to this distribution. We offer a rigorous mathematical analysis using a doubly stochastic model of the images, which not only provides the theoretical explanations necessary, but also leads to insights about various other observations from the literature. This model also allows us to investigate how certain changes in the image statistics could affect the DCT coefficient distributions.},
  annotation = {DCT ç³»æ•° æ•°å­¦åˆ†æ},
  file       = {E\:\\Documents\\Zotero\\storage\\7JSMWCYC\\2000 - A mathematical analysis of the DCT coefficient distributions for images - Lam å’Œ Goodman.pdf},
  journal    = {IEEE Transactions on Image Processing},
  keywords   = {central limit theorem,DCT coefficient distributions,discrete cosine transforms,Discrete cosine transforms,doubly stochastic model,empirical data,Gaussian distribution,Histograms,image coding,Image coding,image statistics,Laplace equations,Laplacian distribution,mathematical analysis,Mathematical analysis,Mathematical model,standard pictures,statistical distributions,Statistical distributions,stochastic processes,Stochastic processes,Testing,transform coding},
  number     = {10},
  note       = {doi: 10.1109/83.869177}
}

@article{DCTDSTchoose,
  title    = {{{DCT}}/{{DST}}-Based Transform Coding for Intra Prediction in {{Image}}/{{Video}} Coding},
  author   = {Saxena, Ankur and Fernandes, Felix C.},
  year     = {2013},
  month    = oct,
  volume   = {22},
  pages    = {3974--3981},
  issn     = {1941-0042},
  doi      = {10.1109/TIP.2013.2265882},
  abstract = {In this paper, we present a DCT/DST based transform scheme that applies either the conventional DCT or type-7 DST for all the video-coding intra-prediction modes: vertical, horizontal, and oblique. Our approach is applicable to any block-based intra prediction scheme in a codec that employs transforms along the horizontal and vertical direction separably. Previously, Han, Saxena, and Rose showed that for the intra-predicted residuals of horizontal and vertical modes, the DST is the optimal transform with performance close to the KLT. Here, we prove that this is indeed the case for the other oblique modes. The optimal choice of using DCT or DST is based on intra-prediction modes and requires no additional signaling information or rate-distortion search. The DCT/DST scheme presented in this paper was adopted in the HEVC standardization in March 2011. Further simplifications, especially to reduce implementation complexity, which remove the mode-dependency between DCT and DST, and simply always use DST for the 4 \texttimes{} 4 intra luma blocks, were adopted in the HEVC standard in July 2012. Simulation results conducted for the DCT/DST algorithm are shown in the reference software for the ongoing HEVC standardization. Our results show that the DCT/DST scheme provides significant BD-rate improvement over the conventional DCT based scheme for intra prediction in video sequences.},
  file     = {E\:\\Documents\\Zotero\\storage\\WRCU6T4P\\2013 - DCTDST-Based Transform Coding for Intra Prediction in ImageVideo Coding - Saxena å’Œ Fernandes.pdf;E\:\\Documents\\Zotero\\storage\\833FSA4P\\6522806.html},
  journal  = {IEEE Transactions on Image Processing},
  keywords = {BD-rate improvement,block-based intraprediction scheme,codec,compression,conventional DCT,DCT,DCT-DST-based transform coding,discrete cosine transforms,DST,HEVC,HEVC standardization,horizontal direction,image sequences,image-video coding,implementation complexity reduction,intraluma blocks,intrapredicted residual,oblique mode,optimal transform,rate-distortion search,reference software,signaling information,transform,transform coding,type-7 DST,vertical direction,video codecs,video coding,Video coding,video sequences,video-coding intraprediction mode},
  number   = {10},
  note     = {doi: 10.1109/TIP.2013.2265882}
}

@article{EfficientMultiplelinebasedIntra,
  title    = {Efficient Multiple-Line-Based Intra Prediction for {{HEVC}}},
  author   = {Li, Jiahao and Li, Bin and Xu, Jizheng and Xiong, Ruiqin},
  year     = {2018},
  month    = apr,
  volume   = {28},
  pages    = {947--957},
  issn     = {1051-8215, 1558-2205},
  doi      = {10.1109/TCSVT.2016.2633377},
  abstract = {Traditional intra prediction usually utilizes the nearest reference line to generate the predicted block when considering strong spatial correlation. However, this kind of single-line-based method does not always work well due to at least two issues. One is the incoherence caused by the signal noise or the texture of other objects, where this texture deviates from the inherent texture of the current block. The other reason is that the nearest reference line usually has worse reconstruction quality in block-based video coding. Due to these two issues, this paper proposes an efficient multiple-line-based intra-prediction scheme to improve coding efficiency. Besides the nearest reference line, further reference lines are also utilized. The further reference lines with a relatively higher quality can provide potentially better prediction. At the same time, the residue compensation is introduced to calibrate the prediction of boundary regions in a block when we utilize further reference lines. To speed up the encoding process, this paper designs several fast algorithms. The experimental results show that compared with HM-16.9, the proposed fast search method achieves a 2.0\% bit saving on average and up to 3.7\% by increasing the encoding time by 112\%.},
  file     = {E\:\\Documents\\Zotero\\storage\\RXX6VMZA\\2018 - Efficient Multiple-Line-Based Intra Prediction for HEVC - Li ç­‰ã€‚.pdf},
  journal  = {IEEE Transactions on Circuits and Systems for Video Technology},
  number   = {4},
  note     = {doi: 10.1109/TCSVT.2016.2633377}
}

@book{FastFourierTransform,
  title     = {Fast {{Fourier Transform}} - {{Algorithms}} and {{Applications}}},
  author    = {Rao, K. R. and Kim, Do Nyeon and Hwang, Jae Jeong},
  year      = {2010},
  publisher = {{Springer Netherlands}},
  doi       = {10.1007/978-1-4020-6629-0},
  abstract  = {Fast Fourier Transform - Algorithms and Applications presents an introduction to the principles of the fast Fourier transform (FFT). It covers FFTs, frequency domain filtering, and applications to video and audio signal processing. As fields like communications, speech and image processing, and related areas are rapidly developing, the FFT as one of the essential parts in digital signal processing has been widely used. Thus there is a pressing need from instructors and students for a book dealing with the latest FFT topics. Fast Fourier Transform - Algorithms and Applications provides a thorough and detailed explanation of important or up-to-date FFTs. It also has adopted modern approaches like MATLAB examples and projects for better understanding of diverse FFTs. Fast Fourier Transform - Algorithms and Applications is designed for senior undergraduate and graduate students, faculty, engineers, and scientists in the field, and self-learners to understand FFTs and directly apply them to their fields, efficiently. It is designed to be both a text and a reference. Thus examples, projects and problems all tied with MATLAB, are provided for grasping the concepts concretely. It also includes references to books and review papers and lists of applications, hardware/software, and useful websites. By including many figures, tables, bock diagrams and graphs, this book helps the reader understand the concepts of fast algorithms readily and intuitively. It provides new MATLAB functions and MATLAB source codes. The material in Fast Fourier Transform - Algorithms and Applications is presented without assuming any prior knowledge of FFT. This book is for any professional who wants to have a basic understanding of the latest developments in and applications of FFT. It provides a good reference for any engineer planning to work in this field, either in basic implementation or in research and development.},
  file      = {E\:\\Documents\\Zotero\\storage\\KD47F9S3\\2010 - Fast Fourier Transform - Algorithms and Applications - Rao ç­‰ã€‚.pdf},
  isbn      = {978-1-4020-6628-3},
  series    = {Signals and {{Communication Technology}}},
  note      = {doi: 10.1007/978-1-4020-6629-0}
}

@inproceedings{FuDanIntraArchitecture,
  title      = {A Highly Pipelined {{VLSI}} Architecture for All Modes and Block Sizes Intra Prediction in {{HEVC}} Encoder},
  booktitle  = {2013 {{IEEE}} 10th {{International Conference}} on {{ASIC}}},
  author     = {{Cong Liu} and {Weiwei Shen} and {Tianlong Ma} and {Yibo Fan} and {Xiaoyang Zeng}},
  year       = {2013},
  month      = oct,
  pages      = {1--4},
  publisher  = {{IEEE}},
  address    = {{Shenzhen, China}},
  doi        = {10.1109/ASICON.2013.6811849},
  abstract   = {The adoption of 35 prediction modes and quad-tree structure in intra coding of HEVC standard significantly improves the coding efficiency. In this paper, a highly pipelined 16-pixel parallel VLSI architecture of intra prediction in HEVC encoder is proposed, supporting all prediction modes and all block sizes. Original pixels are used to help to decide prediction mode 25 and block partition in the premise of negligible PSNR degradation, and a universal predictor is presented. In order to reduce internal buffers when scanning full-mode and full-size predictions in encoder, post-order traversal is applied to the quad-tree structure blocks. It takes 8967 cycles to complete the intra prediction of a whole 32x32 treeblock, including prediction and the decision of mode and block partition. This design is synthesized with TSMC 65nm CMOS technology. It can 30 run at 600 MHz, supporting real-time encoding of 1080P@30fps video sequence.},
  annotation = {å¤æ—¦ipå¸§å†…é¢„æµ‹æ¶æ„ï¼Œä½¿ç”¨åŸå§‹åƒç´ åšé¢„æµ‹ç¡®å®šæ¨¡å¼ï¼Œå‚è€ƒåƒç´ é‡å»ºå®Œåç”¨é€‰å¥½çš„æ¨¡å¼åšé¢„æµ‹ï¼›ä»åº•å±‚å¼€å§‹æœç´¢ã€‚},
  file       = {E\:\\Documents\\Zotero\\storage\\UH464SCD\\2013 - A highly pipelined VLSI architecture for all modes and block sizes intra prediction in HEVC encoder - Cong Liu ç­‰ã€‚.pdf},
  isbn       = {978-1-4673-6417-1 978-1-4673-6415-7 978-1-4673-6416-4},
  note       = {doi: 10.1109/ASICON.2013.6811849}
}

@article{FullyConnectedNetworkbased,
  title    = {Fully Connected Network-Based Intra Prediction for Image Coding},
  author   = {Li, Jiahao and Li, Bin and Xu, Jizheng and Xiong, Ruiqin and Gao, Wen},
  year     = {2018},
  month    = jul,
  volume   = {27},
  pages    = {3236--3247},
  issn     = {1941-0042},
  doi      = {10.1109/TIP.2018.2817044},
  abstract = {This paper proposes a deep learning method for intra prediction. Different from traditional methods utilizing some fixed rules, we propose using a fully connected network to learn an end-to-end mapping from neighboring reconstructed pixels to the current block. In the proposed method, the network is fed by multiple reference lines. Compared with traditional single line-based methods, more contextual information of the current block is utilized. For this reason, the proposed network has the potential to generate better prediction. In addition, the proposed network has good generalization ability on different bitrate settings. The model trained from a specified bitrate setting also works well on other bitrate settings. Experimental results demonstrate the effectiveness of the proposed method. When compared with high efficiency video coding reference software HM-16.9, our network can achieve an average of 3.4\% bitrate saving. In particular, the average result of 4K sequences is 4.5\% bitrate saving, where the maximum one is 7.4\%.},
  file     = {E\:\\Documents\\Zotero\\storage\\CK26NTTQ\\2018 - Fully Connected Network-Based Intra Prediction for Image Coding - Li ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\IVC8ULHF\\8319436.html},
  journal  = {IEEE Transactions on Image Processing},
  keywords = {4K sequences,Bit rate,bitrate settings,current block,deep learning,deep learning method,Encoding,end-to-end mapping,fully connected network,graph theory,HEVC,image coding,Image coding,image reconstruction,Image reconstruction,image sequences,intra prediction,intraprediction,learning (artificial intelligence),Machine learning,multiple reference lines,network theory (graphs),pixels reconstruction,prediction theory,Software,Transform coding},
  number   = {7},
  note     = {doi: 10.1109/TIP.2018.2817044}
}

@inproceedings{GeneticAlgorithmPixelCompressYiChuanSuanFa,
  title      = {Image Compression Based on Genetic Algorithm Optimization},
  booktitle  = {2015 2nd {{World Symposium}} on {{Web Applications}} and {{Networking}} ({{WSWAN}})},
  author     = {Omari, Mohammed and Yaichi, Salah},
  year       = {2015},
  month      = mar,
  pages      = {1--5},
  doi        = {10.1109/WSWAN.2015.7210304},
  abstract   = {Image compression has attracted a lot of research since the beginning of Internet era and telecommunication. Enhancing image compression quality and ratio was achieved through several approaches such as neural networks and discrete transforms. However, other heuristic and bio-inspired methods such as genetic algorithms are still under experimentation. In this paper, we introduced a new image compression mechanism based on exploiting the relationship between fractional numbers and their corresponding quotient representation. Each sub-image is mapped to a fractional number based on the RGB representation, and then reduced to an efficient quotient. The appeal of using genetic algorithms is explained by the massive search to find a close fraction that is reduced to short quotient. Our method showed a considerable compression ratio when the least significant bits of each byte are altered, hence, the image quality is preserved while achieving high compression ratio.},
  annotation = {é—ä¼ ç®—æ³•å‹ç¼©åƒç´ æ•°å€¼},
  file       = {E\:\\Documents\\Zotero\\storage\\U96UTKKM\\Omari å’Œ Yaichi - 2015 - Image compression based on genetic algorithm optim.pdf;E\:\\Documents\\Zotero\\storage\\FLZGVK5X\\7210304.html},
  keywords   = {Biological cells,data compression,Fractal image,fractional numbers,genetic algorithm optimization,genetic algorithms,Genetic algorithms,image coding,Image coding,image colour analysis,image compression quality enhancement,image compression ratio enhancement,image representation,Internet era,least significant bits,lossy compression,number theory,quotient representation,rational numbers,RGB representation,Sociology,Statistics,telecommunication,Wavelet transforms},
  note       = {doi: 10.1109/WSWAN.2015.7210304}
}

@article{H264Overview,
  title      = {The {{H}}.264/{{MPEG4}} Advanced Video Coding Standard and Its Applications},
  author     = {Marpe, D. and Wiegand, T. and Sullivan, G. J.},
  year       = {2006},
  month      = aug,
  volume     = {44},
  pages      = {134--143},
  issn       = {1558-1896},
  doi        = {10.1109/MCOM.2006.1678121},
  abstract   = {H.264/MPEG4-AVC is the latest video coding standard of the ITU-T video coding experts group (VCEG) and the ISO/IEC moving picture experts group (MPEG). H.264/MPEG4-AVC has recently become the most widely accepted video coding standard since the deployment of MPEG2 at the dawn of digital television, and it may soon overtake MPEG2 in common use. It covers all common video applications ranging from mobile services and videoconferencing to IPTV, HDTV, and HD video storage. This article discusses the technology behind the new H.264/MPEG4-AVC standard, focusing on the main distinct features of its core coding technology and its first set of extensions, known as the fidelity range extensions (FRExt). In addition, this article also discusses the current status of adoption and deployment of the new standard in various application areas},
  annotation = {H.264ç»¼è¿°å’Œæ ‡å‡†},
  file       = {E\:\\Documents\\Zotero\\storage\\BJNDEN8M\\2006 - The H.264MPEG4 advanced video coding standard and its applications - Marpe ç­‰ã€‚.pdf},
  journal    = {IEEE Communications Magazine},
  keywords   = {core coding technology,Digital TV,fidelity range extensions,H.264-MPEG4 advanced video coding standard,HD video storage,HDTV,High definition video,IEC standards,IPTV,ISO standards,ISO-IEC moving picture experts group,ITU-T video coding experts group,mobile services,MPEG 4 Standard,MPEG standards,telecommunication services,Teleconferencing,video coding,Video coding,videoconferencing},
  number     = {8},
  note       = {doi: 10.1109/MCOM.2006.1678121}
}

@article{H264TwoLayerLosslessCoding,
  title      = {Improved {{H}}.264/{{AVC}} Lossless Intra Coding with Two-Layered Residual Coding ({{TRC}})},
  author     = {{Seung-Hwan Kim} and {Je-Won Kang} and Kuo, C.-C Jay},
  year       = {2011},
  month      = jul,
  volume     = {21},
  pages      = {1005--1010},
  issn       = {1051-8215, 1558-2205},
  doi        = {10.1109/TCSVT.2011.2133170},
  abstract   = {A lossless image coding method, known as the two-layered residual coding (TRC) scheme, is proposed in this letter. After the H.264/AVC lossy intra prediction, we propose an advanced scheme for residual coding, which consists of two residual coders in cascade. The first-layer residual coder is conducted via transform and quantization with a coarser quantization parameter. The second-layer residual coder is a bitplane coding method. It is shown experimentally that the TRC scheme outperforms the H.264/AVC lossless intra coding with an averaged bit rate saving of about 24\%.},
  annotation = {ä¸¤å±‚æ®‹å·®ç¼–ç ï¼Œåœ¨æœ‰æŸçš„åŸºç¡€ä¸Šå¥—ä¸€å±‚ä¿®æ­£å€¼çš„ç¼–ç ï¼Œå®ç°æ— æŸï¼ˆH.264ï¼‰},
  file       = {E\:\\Documents\\Zotero\\storage\\2CPXH2RJ\\2011 - Improved H.264AVC Lossless Intra Coding With Two-Layered Residual Coding (TRC) - Seung-Hwan Kim ç­‰ã€‚.pdf},
  journal    = {IEEE Transactions on Circuits and Systems for Video Technology},
  number     = {7},
  note       = {doi: 10.1109/TCSVT.2011.2133170}
}

@article{H265Overview,
  title      = {Overview of the {{High Efficiency Video Coding}} ({{HEVC}}) {{Standard}}},
  author     = {Sullivan, Gary J. and Ohm, Jens-Rainer and Han, Woo-Jin and Wiegand, Thomas},
  year       = {2012},
  month      = dec,
  volume     = {22},
  pages      = {1649--1668},
  issn       = {1051-8215, 1558-2205},
  doi        = {10.1109/TCSVT.2012.2221191},
  abstract   = {High Efficiency Video Coding (HEVC) is currently being prepared as the newest video coding standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goal of the HEVC standardization effort is to enable significantly improved compression performance relative to existing standards\textemdash in the range of 50\% bit-rate reduction for equal perceptual video quality. This paper provides an overview of the technical features and characteristics of the HEVC standard.},
  annotation = {H265ç»¼è¿°},
  file       = {E\:\\Documents\\Zotero\\storage\\LDIABWYE\\2012 - Overview of the High Efficiency Video Coding (HEVC) Standard - Sullivan ç­‰ã€‚.pdf},
  journal    = {IEEE Transactions on Circuits and Systems for Video Technology},
  number     = {12},
  note       = {doi: 10.1109/TCSVT.2012.2221191}
}

@article{H266Overview,
  title    = {Developments in {{International Video Coding Standardization After AVC}}, {{With}} an {{Overview}} of {{Versatile Video Coding}} ({{VVC}})},
  author   = {Bross, Benjamin and Chen, Jianle and Ohm, Jens-Rainer and Sullivan, Gary J. and Wang, Ye-Kui},
  year     = {2021},
  pages    = {1--31},
  issn     = {1558-2256},
  doi      = {10.1109/JPROC.2020.3043399},
  abstract = {In the last 17 years, since the finalization of the first version of the now-dominant H.264/Moving Picture Experts Group-4 (MPEG-4) Advanced Video Coding (AVC) standard in 2003, two major new generations of video coding standards have been developed. These include the standards known as High Efficiency Video Coding (HEVC) and Versatile Video Coding (VVC). HEVC was finalized in 2013, repeating the ten-year cycle time set by its predecessor and providing about 50\% bit-rate reduction over AVC. The cycle was shortened by three years for the VVC project, which was finalized in July 2020, yet again achieving about a 50\% bit-rate reduction over its predecessor (HEVC). This article summarizes these developments in video coding standardization after AVC. It especially focuses on providing an overview of the first version of VVC, including comparisons against HEVC. Besides further advances in hybrid video compression, as in previous development cycles, the broad versatility of the application domain that is highlighted in the title of VVC is explained. Included in VVC is the support for a wide range of applications beyond the typical standard- and high-definition camera-captured content codings, including features to support computer-generated/screen content, high dynamic range content, multilayer and multiview coding, and support for immersive media such as 360\textdegree{} video.},
  file     = {E\:\\Documents\\Zotero\\storage\\AJA57NEU\\2021 - Developments in International Video Coding Standardization After AVC, With an Overview of Versatile Video Coding (VVC) - Bross ç­‰ã€‚.pdf},
  journal  = {Proceedings of the IEEE},
  keywords = {Compression,Decoding,Encoding,H.265,H.266,High Efficiency Video Coding (HEVC),Joint Video Experts Team (JVET),Moving Picture Experts Group (MPEG),Quantization (signal),standards,Standards,Streaming media,Transforms,versatile supplemental enhancement information (VSEI),Versatile Video Coding (VVC),video,video coding,Video coding,Video Coding Experts Group (VCEG),video compression.},
  note     = {doi: 10.1109/JPROC.2020.3043399}
}

@inproceedings{H266OverviewAbandoned,
  title      = {Versatile {{Video Coding}} \textendash{} {{Algorithms}} and {{Specification}}},
  booktitle  = {2020 {{IEEE International Conference}} on {{Visual Communications}} and {{Image Processing}} ({{VCIP}})},
  author     = {Wien, M. and Bross, B.},
  year       = {2020},
  month      = dec,
  pages      = {1--3},
  issn       = {2642-9357},
  doi        = {10.1109/VCIP49819.2020.9301820},
  abstract   = {The tutorial provides an overview on the latest emerging video coding standard VVC (Versatile Video Coding) to be jointly published by ITU-T and ISO/IEC. It has been developed by the Joint Video Experts Team (JVET), consisting of ITU-T Study Group 16 Question 6 (known as VCEG) and ISO/IEC JTC 1/SC 29/WG 11 (known as MPEG). VVC has been designed to achieve significantly improved compression capability compared to previous standards such as HEVC, and at the same time to be highly versatile for effective use in a broadened range of applications. Some key application areas for the use of VVC particularly include ultra-high-definition video (e.g. 4K or 8K resolution), video with a high dynamic range and wide colour gamut (e.g., with transfer characteristics specified in Rec. ITU-R BT.2100), and video for immersive media applications such as 360\textdegree{} omnidirectional video, in addition to the applications that have commonly been addressed by prior video coding standards. Important design criteria for VVC have been low computational complexity on the decoder side and friendliness for parallelization on various algorithmic levels. VVC is planned to be finalized by July 2020 and is expected to enter the market very soon.The tutorial details the video layer coding tools specified in VVC and develops the concepts behind the selected design choices. While many tools or variants thereof have been available before, the VVC design reveals many improvements compared to previous standards which result in compression gain and implementation friendliness. Furthermore, new tools such as the Adaptive Loop Filter, or Matrix-based Intra Prediction have been adopted which contribute significantly to the overall performance. The high-level syntax of VVC has been re-designed compared to previous standards such as HEVC, in order to enable dynamic sub-picture access as well as major scalability features already in version 1 of the specification.},
  annotation = {VVCç»¼è¿°},
  file       = {E\:\\Documents\\Zotero\\storage\\M7A95RM3\\2020 - Versatile Video Coding â€“ Algorithms and Specification - Wien å’Œ Bross.pdf},
  keywords   = {High efficiency video coding,IEC Standards,ISO Standards,Standards,Tools,Transform coding,Tutorials},
  note       = {doi: 10.1109/VCIP49819.2020.9301820}
}

@inproceedings{HEVCCommonTestConditionsCTC,
  title      = {Common Test Conditions and Software Reference Configurations},
  booktitle  = {{{JCTVC}}-{{L1100}}},
  author     = {Bossen, Frank and others},
  year       = {2013},
  volume     = {12},
  annotation = {HEVCé€šç”¨æµ‹è¯•é…ç½®}
}

@inproceedings{HEVCExSCCTestConditions,
  title      = {Common Test Conditions and Software Reference Configurations for {{HEVC}} Range Extensions},
  booktitle  = {{{JCT}}-{{VC P1006}}, 16th {{Meeting}} of {{JCT}}-{{VC}}},
  author     = {Rosewarne, C and Sharman, K and Flynn, D},
  year       = {2014},
  pages      = {1--10},
  annotation = {HEVCæ‰©å±•æ ‡å‡†æµ‹è¯•é…ç½®}
}

@article{HEVCSCCOverview,
  title    = {Overview of the Emerging {{HEVC}} Screen Content Coding Extension},
  author   = {Xu, J. and Joshi, R. and Cohen, R. A.},
  year     = {2016},
  month    = jan,
  volume   = {26},
  pages    = {50--62},
  issn     = {1558-2205},
  doi      = {10.1109/TCSVT.2015.2478706},
  abstract = {A screen content coding (SCC) extension to High Efficiency Video Coding (HEVC) is currently under development by the Joint Collaborative Team on Video Coding, which is a joint effort from the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goal of the HEVC-SCC standardization effort is to enable significantly improved compression performance for videos containing a substantial amount of still or moving rendered graphics, text, and animation rather than, or in addition to, camera-captured content. This paper provides an overview of the technical features and characteristics of the current HEVC-SCC test model and related coding tools, including intra-block copy, palette mode, adaptive color transform, and adaptive motion vector resolution. The performance of the SCC extension is compared against existing standards in terms of bitrate savings at equal distortion. HEVCå±å¹•å›¾åƒç¼–ç æ‰©å±•æ ‡å‡†(HEVC Screen Content Coding Extension, HEVC-SCC)},
  file     = {E\:\\Documents\\Zotero\\storage\\A79ZG7JA\\2016 - Overview of the Emerging HEVC Screen Content Coding Extension - Xu ç­‰ã€‚.pdf},
  journal  = {IEEE Transactions on Circuits and Systems for Video Technology},
  keywords = {adaptive codes,adaptive color transform,adaptive motion vector resolution,Color,Encoding,HEVC,HEVC screen content coding extension,high efficiency video coding,High Efficiency Video Coding (HEVC),Image color analysis,Indexes,intra-block copy,ISO-IEC moving picture experts group,joint collaborative team on video coding,palette mode,SCC,screen content coding,screen content coding (SCC),Standards,transform coding,Transforms,video coding,Video coding},
  number   = {1},
  note     = {doi: 10.1109/TCSVT.2015.2478706}
}

@misc{HEVCsoftwareHM16,
  title      = {Bossen {{F}}, {{Suehring K}}, {{Iwamura S}}, et al. {{H}}.265/{{HEVC HM Reference Software}} [{{CP}}/{{OL}}]. [2021-03-18]. {{https://vcgit.hhi.fraunhofer.de/jvet/HM}}},
  annotation = {HEVCå‚è€ƒè½¯ä»¶HM16}
}

@inproceedings{ImprovementsTZSearch,
  title     = {Improvements to {{TZ}} Search Motion Estimation Algorithm for Multiview Video Coding},
  booktitle = {2012 19th {{International Conference}} on {{Systems}}, {{Signals}} and {{Image Processing}} ({{IWSSIP}})},
  author    = {Purnachand, N. and Alves, Luis Nero and Navarro, Antonio},
  year      = {2012},
  month     = apr,
  pages     = {388--391},
  issn      = {2157-8702},
  abstract  = {This paper, proposes improvements to TZ search motion estimation algorithm with reference to its implementation in JMVC reference software. In TZS, the search patterns that are implemented are 8-point diamond and 8-point square. When these are replaced with hexagonal patterns, there is a large improvement in encoding time. Further, the TZS algorithm is improved by changing the searching threshold for each grid in the search area. Simulation results show that the overall encoding time can be reduced by almost 50\% compared to TZS algorithm, while maintaining the same PSNR and bitrate.},
  file      = {E\:\\Documents\\Zotero\\storage\\7M5MWIH6\\2012 - Improvements to TZ search motion estimation algorithm for multiview video coding - Purnachand ç­‰ã€‚.pdf},
  keywords  = {Bit rate,Diamond-like carbon,Encoding,H.264,JMVC,Motion estimation,Motion Estimation,MVC,Prediction algorithms,PSNR,Software algorithms}
}

@article{IntergerDCTs,
  title    = {Integer {{DCTs}} and Fast Algorithms},
  author   = {Zeng, Yonghong and Cheng, Lizhi and Bi, Guoan and Kot, A.C.},
  year     = {2001},
  month    = nov,
  volume   = {49},
  pages    = {2774--2782},
  issn     = {1941-0476},
  doi      = {10.1109/78.960425},
  abstract = {A method is proposed to factor the type-II discrete cosine transform (DCT-II) into lifting steps and additions. After approximating the lifting matrices, we get a new type-II integer discrete cosine transform (IntDCT-II) that is float-point multiplication free. Based on the relationships among the various types of DCTs, we can generally factor any DCTs into lifting steps and additions and then get four types of integer DCTs, which need no float-point multiplications. By combining the polynomial transform and the one-dimensional (1-D) integer cosine transform, a two-dimensional (2-D) integer discrete cosine transform is proposed. The proposed transform needs only integer operations and shifts. Furthermore, it is nonseparable and requires a far fewer number of operations than that used by the corresponding row-column 2-D integer discrete cosine transform.},
  file     = {E\:\\Documents\\Zotero\\storage\\G23E896G\\2001 - Integer DCTs and fast algorithms - Zeng ç­‰ã€‚.pdf},
  journal  = {IEEE Transactions on Signal Processing},
  keywords = {Bismuth,Data compression,Discrete cosine transforms,Discrete transforms,Feature extraction,Image coding,Mobile computing,Polynomials,Signal processing algorithms,Two dimensional displays},
  number   = {11},
  note     = {doi: 10.1109/78.960425}
}

@misc{JPEGStandardITU,
  title        = {T.81~:~Information Technology - Digital Compression and Coding of Continuous-Tone Still Images - Requirements and Guidelines},
  annotation   = {JPEG ITU æ ‡å‡†},
  howpublished = {https://www.itu.int/rec/T-REC-T.81-199209-I/en}
}

@inproceedings{LatestLosslessIntraCodingAsRef,
  title      = {A Fast Lossless Implementation of the Intra Subpartition Mode for {{VVC}}},
  booktitle  = {2020 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author     = {{De-Lux{\'a}n-Hern{\'a}ndez}, S. and Venugopal, G. and George, V. and Schwarz, H. and Marpe, D. and Wiegand, T.},
  year       = {2020},
  month      = oct,
  pages      = {1118--1122},
  issn       = {2381-8549},
  doi        = {10.1109/ICIP40778.2020.9191103},
  abstract   = {Lossy compression is the main target of the upcoming video coding standard Versatile Video Coding (VVC). However, lossless coding is supported in VVC by utilizing a certain encoder configuration. Particularly, the Transform Skip Mode (TSM) is always selected at the block level to bypass the transform stage (together with a QP that results in the same output as input at the quantization stage). Consequently, the Intra Subpartition (ISP) coding mode cannot be used for lossless coding, considering that its combination with TSM is not supported in VVC because it does not provide a significant coding benefit for the lossy common test conditions. For this reason, it is proposed to enable such a combination for the benefit of lossless coding. Besides, the encoder search has been optimized to improve the trade-off between compression benefit and encoder run-time. Experimental results show a 0.71\% coding gain with a corresponding encoder run-time of 111\%.},
  annotation = {æœ€æ–°çš„æ— æŸåº”ç”¨ï¼Œåšå‚è€ƒæ–‡çŒ®},
  file       = {E\:\\Documents\\Zotero\\storage\\56LRRNEL\\2020 - A Fast Lossless Implementation Of The Intra Subpartition Mode For VVC - De-LuxÃ¡n-HernÃ¡ndez ç­‰ã€‚.pdf},
  keywords   = {coding gain,Copper,data compression,Decoding,Encoding,Estimation,fast encoder search,fast lossless implementation,intra prediction,Intra Subpartition coding mode,Intra Subpartition Mode,intra subpartitions,ISP,lossless coding,lossy common test conditions,lossy compression,rate distortion theory,significant coding benefit,standard Versatile Video Coding,Tools,Transform Skip Mode,transform stage,Transforms,TSM,upcoming video,video coding,Video coding,VVC},
  note       = {doi: 10.1109/ICIP40778.2020.9191103}
}

@phdthesis{LineCodeDocPaper,
  title      = {{åŸºäºè¡Œç»“æ„çš„å›¾åƒç¼–ç }},
  author     = {å½­, ç§€è²},
  year       = {2012},
  abstract   = {éšç€æ•°å­—å›¾åƒåœ¨å¤šåª’ä½“ä¸­çš„å¹¿æ³›åº”ç”¨ã€å›¾åƒåˆ†è¾¨ç‡çš„ä¸æ–­å¢åŠ ä»¥åŠæ–°çš„å›¾åƒè¡¨ç¤ºå½¢å¼çš„è¯ç”Ÿ,å›¾åƒç¼–ç æ— è®ºåœ¨ç¼–ç æ€§èƒ½è¿˜æ˜¯è®¡ç®—ã€å­˜å‚¨å¤æ‚åº¦ä¸Šéƒ½é¢ä¸´ç€æ–°çš„æŒ‘æˆ˜ã€‚ç°ä»Šä¸»æµçš„å›¾åƒå’Œå¸§å†…ç¼–ç æŠ€æœ¯éƒ½é‡‡ç”¨äº†åŸºäºå—ç»“æ„çš„ç¼–ç ,å…¶ä¸­æœ€å…ˆè¿›çš„ç¼–ç æ ‡å‡†H.264/AVCåœ¨å¸§å†…ç¼–ç æ—¶é‡‡ç”¨äº†å—ç»“æ„é¢„æµ‹å’ŒäºŒç»´å˜æ¢çš„æ–¹æ³•ã€‚ç„¶è€Œ,å—å—ç»“æ„çš„é™åˆ¶,å…¶é¢„æµ‹çš„æ€§èƒ½å¹¶ä¸å¥½,ä»è€Œå½±å“äº†å—ç»“æ„ç¼–ç çš„æ€§èƒ½ã€‚å¦ä¸€æ–¹é¢,å—ç»“æ„çš„ç¼–ç ä¸ºäº†æ¶ˆé™¤å—é—´çš„ç›¸å…³æ€§å¼•å…¥äº†è¾ƒå¼ºçš„å—é—´ç¼–ç ä¾èµ–æ€§,ä½¿å¾—å®ƒä¸é€‚äºé«˜å¹¶è¡Œåº¦çš„ç¼–ç æ¥æé«˜ç¼–ç é€Ÿåº¦,è€Œå—ç»“æ„çš„ç¼–ç ä»å­˜å‚¨å¤æ‚åº¦ä¸Šæ¥è¯´ä¹Ÿä¸æ˜¯æœ€ä¼˜çš„é€‰æ‹©ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜,æœ¬æ–‡ä»æ”¹å˜ç¼–ç ç»“æ„çš„è§’åº¦å…¥æ‰‹,æå‡ºäº†åŸºäºè¡Œç»“æ„çš„ç¼–ç ã€‚ 	æœ¬æ–‡é¦–å…ˆ...},
  annotation = {è¡Œç¼–ç  ä¸­ç§‘å¤§åšå£«è®ºæ–‡},
  file       = {E\:\\Documents\\Zotero\\storage\\Z46VVE7U\\å½­ - 2012 - åŸºäºè¡Œç»“æ„çš„å›¾åƒç¼–ç .caj},
  keywords   = {block-based coding,broadcast,distributed source coding,H.264/AVC,image coding,parallel coding,prediction,transform,åˆ†å¸ƒå¼ç¼–ç ,å˜æ¢H.264/AVCå—ç»“æ„çš„ç¼–ç ,å›¾åƒç¼–ç ,å¹¶è¡Œç¼–ç ,å¹¿æ’­ä¼ è¾“,é¢„æµ‹},
  language   = {ä¸­æ–‡;},
  school     = {ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦},
  type       = {{åšå£«}}
}

@article{LineCodeSaveMemoryEnergyEfficient,
  title      = {An Energy-Efficient Low-Memory Image Compression System for Multimedia {{IoT}} Products},
  author     = {Lee, Seong-Won and Kim, Ho-Young},
  year       = {2018},
  month      = dec,
  volume     = {2018},
  pages      = {87},
  issn       = {1687-5281},
  doi        = {10.1186/s13640-018-0333-3},
  abstract   = {Emerging Internet of things (IoT) technologies have rapidly expanded to multimedia applications, including highresolution image transmission. However, handling image data in IoT products with limited battery capacity requires low-complexity and small-size solutions such as low-memory compression techniques. The objective of this paper is to propose a line-based compression system based on four-level two-line discrete wavelet transform and adaptive line prediction. Bit stream is generated by multiplexing various frequency components with run-level coding combined with Huffman coding. The proposed system also includes a new bit rate control algorithm that could significantly improve image quality consistency in one frame. The proposed low-memory compression system can retain image quality for visually lossless compression criteria over the whole image frame. It can simultaneously lower total system power consumption in multimedia IoT products better than other existing low-memory compression techniques.},
  annotation = {è¡Œç¼–ç  èŠ‚çœå­˜å‚¨ç©ºé—´},
  file       = {E\:\\Documents\\Zotero\\storage\\N4GL59SF\\Lee å’Œ Kim - 2018 - An energy-efficient low-memory image compression s.pdf},
  journal    = {EURASIP Journal on Image and Video Processing},
  number     = {1},
  note       = {doi: 10.1186/s13640-018-0333-3}
}

@article{LOCOi,
  title      = {The {{LOCO}}-i Lossless Image Compression Algorithm: Principles and Standardization into {{JPEG}}-{{LS}}},
  shorttitle = {The {{LOCO}}-i Lossless Image Compression Algorithm},
  author     = {Weinberger, M. J. and Seroussi, G. and Sapiro, G.},
  year       = {2000},
  month      = aug,
  volume     = {9},
  pages      = {1309--1324},
  issn       = {1941-0042},
  doi        = {10.1109/83.855427},
  abstract   = {LOCO-I (LOw COmplexity LOssless COmpression for Images) is the algorithm at the core of the new ISO/ITU standard for lossless and near-lossless compression of continuous-tone images, JPEG-LS. It is conceived as a "low complexity projection" of the universal context modeling paradigm, matching its modeling unit to a simple coding unit. By combining simplicity with the compression potential of context models, the algorithm "enjoys the best of both worlds." It is based on a simple fixed context model, which approaches the capability of the more complex universal techniques for capturing high-order dependencies. The model is tuned for efficient performance in conjunction with an extended family of Golomb (1966) type codes, which are adaptively chosen, and an embedded alphabet extension for coding of low-entropy image regions. LOCO-I attains compression ratios similar or superior to those obtained with state-of-the-art schemes based on arithmetic coding. Moreover, it is within a few percentage points of the best available compression ratios, at a much lower complexity level. We discuss the principles underlying the design of LOCO-I, and its standardization into JPEC-LS.},
  annotation = {æ–°Planaræ¥æºLOCO-i},
  file       = {E\:\\Documents\\Zotero\\storage\\Y9L3FUA9\\2000 - The LOCO-I lossless image compression algorithm principles and standardization into JPEG-LS - Weinberger ç­‰ã€‚.pdf},
  journal    = {IEEE Transactions on Image Processing},
  keywords   = {Arithmetic,arithmetic codes,arithmetic coding,code standards,coding unit,compression ratios,computational complexity,Context modeling,continuous-tone images,data compression,Data compression,Decoding,efficient performance,embedded alphabet extension,entropy,fixed context model,Golomb-type codes,high-order dependencies,image coding,Image coding,Inference algorithms,ISO standards,ISO/ITU standard,JPEG-LS,Laboratories,LOGO-I lossless image compression algorithm,lossless compression,low complexity lossless compression for images,low complexity projection,low-entropy image regions,modeling unit,near-lossless compression,Solid modeling,standardisation,standardization,Standardization,universal context modeling paradigm},
  number     = {8},
  note       = {doi: 10.1109/83.855427}
}

@article{LosslessI2ITransformTCSVT,
  title    = {Lossless Image and Intra-Frame Compression with Integer-to-Integer {{DST}}},
  author   = {Kamisli, F.},
  year     = {2019},
  month    = feb,
  volume   = {29},
  pages    = {502--516},
  issn     = {1558-2205},
  doi      = {10.1109/TCSVT.2017.2787638},
  abstract = {Video coding standards are primarily designed for efficient lossy compression, but it is also desirable to support efficient lossless compression within video coding standards using small modifications to the lossy coding architecture. A simple approach is to skip transform and quantization, and simply entropy code the prediction residual. However, this approach is inefficient at compression. A more efficient and popular approach is to skip transform and quantization but also process the residual block in some modes with differential pulse code modulation (DPCM), along the horizontal or vertical direction, prior to entropy coding. This paper explores an alternative approach based on processing the residual block with integer-to-integer (i2i) transforms. I2i transforms can map integer pixels to integer transform coefficients without increasing the dynamic range and can be used for lossless compression. We focus on lossless intra coding and develop novel i2i approximations of the odd type-3 discrete sine transform (ODST-3). Experimental results with the high efficiency video coding (HEVC) reference software show that when the developed i2i approximations of the ODST-3 are used along the DPCM method of HEVC, an average 2.7\% improvement of lossless intra frame compression efficiency is achieved over HEVC version 2, which uses only the DPCM method, without a significant increase in computational complexity.},
  file     = {E\:\\Documents\\Zotero\\storage\\P9VFU8TG\\2019 - Lossless Image and Intra-Frame Compression With Integer-to-Integer DST - Kamisli.pdf},
  journal  = {IEEE Transactions on Circuits and Systems for Video Technology},
  keywords = {computational complexity,data compression,differential pulse code modulation,discrete cosine transforms,DPCM method,efficient lossless compression,efficient lossy compression,Entropy coding,HEVC,HEVC version 2,high efficiency video coding reference software,i2i approximations,image coding,Image coding,integer pixels,integer-to-integer DST,integer-to-integer transforms,lossless coding,lossless intra coding,lossless intra frame compression efficiency,lossy coding architecture,odd type-3 discrete sine,ODST-3,prediction residual,Pulse modulation,residual block,Standards,transforms,Transforms,video coding,Video coding,video coding standards},
  number   = {2},
  note     = {doi: 10.1109/TCSVT.2017.2787638}
}

@inproceedings{PSNRSSIM,
  title      = {Image {{Quality Metrics}}: {{PSNR}} vs. {{SSIM}}},
  shorttitle = {Image {{Quality Metrics}}},
  booktitle  = {2010 20th {{International Conference}} on {{Pattern Recognition}}},
  author     = {Hor{\'e}, Alain and Ziou, Djemel},
  year       = {2010},
  month      = aug,
  pages      = {2366--2369},
  issn       = {1051-4651},
  doi        = {10.1109/ICPR.2010.579},
  abstract   = {In this paper, we analyse two well-known objective image quality metrics, the peak-signal-to-noise ratio (PSNR) as well as the structural similarity index measure (SSIM), and we derive a simple mathematical relationship between them which works for various kinds of image degradations such as Gaussian blur, additive Gaussian white noise, jpeg and jpeg2000 compression. A series of tests realized on images extracted from the Kodak database gives a better understanding of the similarity and difference between the SSIM and the PSNR.},
  file       = {E\:\\Documents\\Zotero\\storage\\VSHGNCEW\\2010 - Image Quality Metrics PSNR vs. SSIM - HorÃ© å’Œ Ziou.pdf},
  keywords   = {Additives,Degradation,Image coding,Image quality,image quality metrics,PSNR,Sensitivity,SSIM,Transform coding},
  note       = {doi: 10.1109/ICPR.2010.579}
}

@article{pwmResidualsPiecewiseMapping,
  title      = {Piecewise Mapping in {{HEVC}} Lossless Intra-Prediction Coding},
  author     = {Sanchez, Victor and {Aul{\'i}-Llin{\`a}s}, Francesc and {Serra-Sagrist{\`a}}, Joan},
  year       = {2016},
  month      = sep,
  volume     = {25},
  pages      = {4004--4017},
  issn       = {1941-0042},
  doi        = {10.1109/TIP.2016.2571065},
  abstract   = {The lossless intra-prediction coding modality of the High Efficiency Video Coding standard provides high coding performance while allowing frame-by-frame basis access to the coded data. This is of interest in many professional applications, such as medical imaging, automotive vision, and digital preservation in libraries and archives. Various improvements to lossless intra-prediction coding have been proposed recently, most of them based on sample-wise prediction using differential pulse code modulation (DPCM). Other recent proposals aim at further reducing the energy of intra-predicted residual blocks. However, the energy reduction achieved is frequently minimal due to the difficulty of correctly predicting the sign and magnitude of residual values. In this paper, we pursue a novel approach to this energy-reduction problem using piecewise mapping (pwm) functions. In particular, we analyze the range of values in residual blocks and apply accordingly a pwm function to map specific residual values to unique lower values. We encode the appropriate parameters associated with the pwm functions at the encoder, so that the corresponding inverse pwm functions at the decoder can map values back to the same residual values. These residual values are then used to reconstruct the original signal. This mapping is, therefore, reversible and introduces no losses. We evaluate the pwm functions on 4 \texttimes{} 4 residual blocks computed after DPCM-based prediction for lossless coding of a variety of camera-captured and screen content sequences. Evaluation results show that the pwm functions can attain the maximum bitrate reductions of 5.54\% and 28.33\% for screen content material compared with DPCM-based and block-wise intra-prediction, respectively. Compared with intra-block copy, piecewise mapping can attain the maximum bit-rate reductions of 11.48\% for a camera-captured material.},
  annotation = {æ®‹å·®åˆ†æ®µæ˜ å°„},
  file       = {E\:\\Documents\\Zotero\\storage\\EGC5R5TW\\2016 - Piecewise Mapping in HEVC Lossless Intra-Prediction Coding - Sanchez ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\X7VTMNL5\\7473932.html},
  journal    = {IEEE Transactions on Image Processing},
  keywords   = {Biomedical imaging,coded data,differential pulse code modulation,DPCM,Encoding,HEVC intra-prediction,HEVC lossless intraprediction coding,high efficiency video coding,Image coding,Image edge detection,intrapredicted residual blocks,lossless coding,piecewise mapping,piecewise mapping functions,pulse code modulation,Pulse width modulation,PWM functions,sample wise prediction,SAP,screen content sequences,Transforms,video coding},
  number     = {9},
  note       = {doi: 10.1109/TIP.2016.2571065}
}

@article{SAP-SAP,
  title    = {{{HEVC}} Lossless Coding and Improvements},
  author   = {Zhou, Minhua and Gao, Wen and Jiang, Minqiang and Yu, Haoping},
  year     = {2012},
  month    = dec,
  volume   = {22},
  pages    = {1839--1843},
  issn     = {1558-2205},
  doi      = {10.1109/TCSVT.2012.2221524},
  abstract = {The lossless coding mode of the High Efficiency Video Coding (HEVC) main profile that bypasses transform, quantization, and in-loop filters is described. Compared to the HEVC nonlossless coding mode with the smallest quantization parameter value (i.e., 0 for 8-b video and -12 for 10-b video), the HEVC lossless coding mode provides perfect fidelity and an average bit-rate reduction of 3.2\%-13.2\%. It also significantly outperforms the existing lossless compression solutions, such as JPEG2000 and JPEG-LS for images as well as 7-Zip and WinRAR for data archiving. To further improve the coding efficiency of the HEVC lossless mode, a sample-based angular intra prediction (SAP) method is presented. The SAP employs the same prediction mode signaling method and the sample interpolation method as the HEVC block-based angular prediction, but uses adjacent neighbors for better intra prediction accuracy and performs prediction sample by sample. The experimental results reveal that the SAP provides an additional bit-rate reduction of 1.8\%-11.8\% on top of the HEVC lossless coding mode.},
  file     = {E\:\\Documents\\Zotero\\storage\\KISLCLTK\\2012 - HEVC Lossless Coding and Improvements - Zhou ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\VPV5DZCD\\6317159.html;E\:\\Documents\\Zotero\\storage\\ZWQNC2SC\\6317159.html},
  journal  = {IEEE Transactions on Circuits and Systems for Video Technology},
  keywords = {7-Zip,bit-rate reduction,Block-based angular intra prediction,block-based angular prediction,data archiving,Encoding,HEVC lossless coding,High Efficiency Video Coding (HEVC),high efficiency video coding main profile,Image coding,in-loop filters,interpolation,interpolation method,intraprediction accuracy,JPEG-LS,JPEG2000,lossless coding,lossless compression solutions,nonlossless coding mode,prediction mode signaling method,prediction sample,quantization parameter value,sample-based angular intra prediction (SAP),sample-based angular intraprediction method,SAP method,Streaming media,video coding,Video coding,WinRAR},
  number   = {12},
  note     = {doi: 10.1109/TCSVT.2012.2221524}
}

@inproceedings{SAP-SAP1,
  title      = {Improvements to {{HEVC}} Intra Coding for Lossless Medical Image Compression},
  booktitle  = {2014 {{Data Compression Conference}}},
  author     = {Sanchez, V. and Llin{\`a}s, F. A. and Rapesta, J. B. and Sagrist{\`a}, J. S.},
  year       = {2014},
  month      = mar,
  pages      = {423--423},
  issn       = {2375-0359},
  doi        = {10.1109/DCC.2014.76},
  abstract   = {This works focuses on the High Efficiency Video Coding (HEVC) standard as a compression method to be potentially adopted by the Digital Imaging and Communications in Medicine (DICOM) standard. We are particularly interested in improving the lossless compression efficiency of the intra coding process for grayscale anatomical medical images. We focus on intra coding due to its low complexity and outstanding compression results, as well as the fact that it allows coding high-dimensional medical images on a slice-by-slice basis. This is especially advantageous for cases when only a small set of slices needs to be accessed without the need to decode the entire data set. Based on the characteristics of grayscale anatomical medical images, specifically their large amount of edge information and frequent number of patterns depicted on various directions, we propose improvements to HEVC intra coding based on sample-by-sample (SbS) differential pulse code modulation (DPCM) with equal displacements so the density of prediction modes is constant in all directions. Performance evaluations over MRI, CT and X-ray angiography sequences show that the proposed improvements outperform current HEVC lossless intra coding, achieving average coding gains of 6\%.},
  annotation = {SAPç³»åˆ—SAP-SAP1},
  file       = {E\:\\Documents\\Zotero\\storage\\IU2E9ZJN\\2014 - Improvements to HEVC intra coding for lossless medical image compression - Sanchez ç­‰ã€‚.pdf},
  keywords   = {data compression,Data compression,DICOM,DICOM standard,Digital Imaging and Communications in Medicine standard,DPCM,Encoding,Gray-scale,grayscale anatomical medical images,HEVC intracoding,high efficiency video coding standard,high-dimensional medical image coding,Image coding,lossless compression efficiency,lossless medical image compression,medical image processing,sample-by-sample differential pulse code modulation,SbS,Standards,video coding},
  note       = {doi: 10.1109/DCC.2014.76}
}

@inproceedings{SAP-SAPE,
  title     = {{{HEVC}}-Based Lossless Compression of {{Whole Slide}} Pathology Images},
  booktitle = {2014 {{IEEE Global Conference}} on {{Signal}} and {{Information Processing}} ({{GlobalSIP}})},
  author    = {Sanchez, Victor and {Aul{\'i}-Llin{\`a}s}, Francesc and {Bartrina-Rapesta}, Joan and {Serra-Sagrist{\`a}}, Joan},
  year      = {2014},
  month     = dec,
  pages     = {297--301},
  doi       = {10.1109/GlobalSIP.2014.7032126},
  abstract  = {This paper proposes an HEVC-based method for lossless compression of Whole Slide pathology Images (WSIs). Based on the observation that WSIs usually feature a high number of edges and multidirectional patterns due to the great variety of cellular structures and tissues depicted, we combine the advantages of sample-by-sample differential pulse code modulation (SbS-DPCM) and edge prediction into the intra coding process. The objective is to enhance the prediction performance where strong edge information is encountered. This paper also proposes an implementation of the decoding process that maintains the block-wise coding structure of HEVC when SbS-DPCM and edge prediction are employed. Experimental results on various WSIs show that the proposed method attains average bit-rate savings of 7.67\%.},
  file      = {E\:\\Documents\\Zotero\\storage\\BYXW97AL\\2014 - HEVC-based lossless compression of Whole Slide pathology images - Sanchez ç­‰ã€‚.pdf},
  keywords  = {Big data,Biomedical imaging,Decoding,Encoding,HEVC,Image coding,Image edge detection,intra coding,lossless compression,Video coding,whole slide pathology images},
  note      = {doi: 10.1109/GlobalSIP.2014.7032126}
}

@techreport{SAP-SAPHV,
  title   = {{{RCE2}}: {{Experimental}} Results on {{Test}} 3 and {{Test}} 4},
  author  = {Zhou, M and Budagavi, Madhukar},
  year    = {2013},
  month   = nov,
  address = {{Incheon, Korea}},
  file    = {E\:\\Documents\\Zotero\\storage\\5DAKLDCH\\HM10.0-RangeExt-TI-losslessAnchor_vs_SAP_HVonly.xls;E\:\\Documents\\Zotero\\storage\\PXFLXX6U\\HM10.0-RangeExt-TI-losslessAnchor_vs_SAP.xls;E\:\\Documents\\Zotero\\storage\\ZEFL6KIV\\JCTVC-M0056.doc},
  number  = {Joint Collaborative Team on Video Coding (M0056)}
}

@inproceedings{SAP-SAPHVSWP2DTM,
  title     = {Sample-Based {{Weighted Prediction}} with {{Directional Template Matching}} for {{HEVC}} Lossless Coding},
  booktitle = {2013 {{Picture Coding Symposium}} ({{PCS}})},
  author    = {Wige, Eugen and Yammine, Gilbert and Amon, Peter and Hutter, Andreas and Kaup, Andr{\'e}},
  year      = {2013},
  month     = dec,
  pages     = {305--308},
  doi       = {10.1109/PCS.2013.6737744},
  abstract  = {The recently introduced High Efficiency Video Coding (HEVC) standard is currently further investigated for potential use in professional applications. The considered Range Extensions should on the one hand introduce higher bit depths and additional color formats, and on the other hand the coding efficiency of HEVC for high fidelity compression as well as lossless compression is to be improved. In this paper we investigate and improve the recently introduced Sample-based Weighted Prediction (SWP) for HEVC lossless coding. Although being very efficient for natural video content, the SWP algorithm can be further improved for screen content by using a directional template predictor in cases where the SWP algorithm yields worse prediction. The mainly introduced predictor improves the lossless coding results by up to 9.9\% compared to the unmodified HEVC reference software for lossless compression.},
  file      = {E\:\\Documents\\Zotero\\storage\\MGKUGHSQ\\2013 - Sample-based Weighted Prediction with Directional Template Matching for HEVC lossless coding - Wige ç­‰ã€‚.pdf},
  keywords  = {Encoding,Image coding,Joints,Prediction algorithms,Software algorithms,Standards,Video coding},
  note      = {doi: 10.1109/PCS.2013.6737744}
}

@article{StillImageIntraCompressRatioAllTest,
  title      = {{{OVERVIEW AND BENCHMARKING SUMMARY FOR THE ICIP}} 2016 {{COMPRESSION CHALLENGE}}},
  author     = {Alexiou, Evangelos and Viola, Irene and Krasula, Lukas and Richter, Thomas and Bruylants, Tim and Pinheiro, Antonio and Fliegel, Karel and Rerabek, Martin and Skodras, Athanassios and Schelkens, Peter and Ebrahimi, Touradj},
  year       = {2016},
  pages      = {38},
  annotation = {é™æ€ å¸§å†… å„ç§ç®—æ³•å‹ç¼©ç‡ç»Ÿè®¡},
  file       = {E\:\\Documents\\Zotero\\storage\\RBELLSP6\\Alexiou ç­‰ã€‚ - 2016 - OVERVIEW AND BENCHMARKING SUMMARY FOR THE ICIP 201.pdf}
}

@inproceedings{VVCComplexityAnalysisEncodeTime30xDecodeTime3x,
  title      = {Complexity {{Analysis Of Next}}-{{Generation VVC Encoding And Decoding}}},
  booktitle  = {2020 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author     = {Pakdaman, F. and Adelimanesh, M. A. and Gabbouj, M. and Hashemi, M. R.},
  year       = {2020},
  month      = oct,
  pages      = {3134--3138},
  issn       = {2381-8549},
  doi        = {10.1109/ICIP40778.2020.9190983},
  abstract   = {While the next generation video compression standard, Versatile Video Coding (VVC), provides a superior compression efficiency, its computational complexity dramatically increases. This paper thoroughly analyzes this complexity for both encoder and decoder of VVC Test Model 6, by quantifying the complexity break-down for each coding tool and measuring the complexity and memory requirements for VVC encoding/decoding. These extensive analyses are performed for six video sequences of 720p, 1080p, and 2160p, under Low-Delay (LD), Random-Access (RA), and All-Intra (AI) conditions (a total of 320 encoding/decoding). Results indicate that the VVC encoder and decoder are 5\texttimes{} and 1.5\texttimes{} more complex compared to HEVC in LD, and 31\texttimes{} and 1.8\texttimes{} in AI, respectively. Detailed analysis of coding tools reveals that in LD on average, motion estimation tools with 53\%, transformation and quantization with 22\%, and entropy coding with 7\% dominate the encoding complexity. In decoding, loop filters with 30\%, motion compensation with 20\%, and entropy decoding with 16\%, are the most complex modules. Moreover, the required memory bandwidth for VVC encoding/decoding are measured through memory profiling, which are 30\texttimes{} and 3\texttimes{} of HEVC. The reported results and insights are a guide for future research and implementations of energy-efficient VVC encoder/decoder.},
  annotation = {VVC å¤æ‚åº¦åˆ†æ ç¼–ç  30x è§£ç  3x},
  file       = {E\:\\Documents\\Zotero\\storage\\ZSKQCQF5\\2020 - Complexity Analysis Of Next-Generation VVC Encoding And Decoding - Pakdaman ç­‰ã€‚.pdf},
  keywords   = {complexity analysis,Conferences,Data compression,IEC Standards,Image processing,Indexes,ISO Standards,Tools,Versatile Video Coding (VVC),video coding,video decoding,VVC Test Model (VTM)},
  note       = {doi: 10.1109/ICIP40778.2020.9190983}
}

@inproceedings{VVCCompressRatio40PercentTime15x,
  title      = {Rate-Distortion and Complexity Comparison of {{HEVC}} and {{VVC}} Video Encoders},
  booktitle  = {2020 {{IEEE}} 11th {{Latin American Symposium}} on {{Circuits}} \& {{Systems}} ({{LASCAS}})},
  author     = {Siqueira, Icaro and Correa, Guilherme and Grellert, Mateus},
  year       = {2020},
  month      = feb,
  pages      = {1--4},
  publisher  = {{IEEE}},
  address    = {{San Jose, Costa Rica}},
  doi        = {10.1109/LASCAS45839.2020.9069036},
  abstract   = {Video-coding systems have presented significant improvements driven by the wide adoption of video streaming technologies combined with demands for better quality from users. The most recent video-coding standard from JCT-VC, named High Efficiency Video Coding, greatly improved the compression rate compared to its predecessor, H.264/AVC, but an even better performance must be pursued to accommodate future technologies. This article presents a comparison between the current state-of-art HEVC standard with the most recent project that is being conducted by the same group of experts, entitled Versatile Video Coding (VVC). According to experimental results obtained using similar configurations for both encoders, the VVC reference software provides significant bit-rate savings of 44.4\% on average when compared to HEVC. However, this compression gains come with high computational costs: the VVC encoding time is on average 10.2 times higher when SIMD are used, and 15.9 times higher without such optimizations.},
  annotation = {VVC å‹ç¼©ç‡ä¼˜åŒ– 40 percent æ—¶é—´ 15x},
  file       = {E\:\\Documents\\Zotero\\storage\\3FJ9AMHU\\2020 - Rate-Distortion and Complexity Comparison of HEVC and VVC Video Encoders - Siqueira ç­‰ã€‚.pdf},
  isbn       = {978-1-72813-427-7},
  note       = {doi: 10.1109/LASCAS45839.2020.9069036}
}

@article{VVCCompressRatioTest30Percent,
  title         = {Comparing {{VVC}}, {{HEVC}} and {{AV1}} Using Objective and Subjective Assessments},
  author        = {Zhang, Fan and Katsenou, Angeliki V. and Afonso, Mariana and Dimitrov, Goce and Bull, David R.},
  year          = {2020},
  month         = mar,
  abstract      = {In this paper, the performance of three state-ofthe-art video codecs: High Efficiency Video Coding (HEVC) Test Model (HM), AOMedia Video 1 (AV1) and Versatile Video Coding Test Model (VTM), are evaluated using both objective and subjective quality assessments. Nine source sequences were carefully selected to offer both diversity and representativeness, and different resolution versions were encoded by all three codecs at pre-defined target bitrates. The compression efficiency of the three codecs are evaluated using two commonly used objective quality metrics, PSNR and VMAF. The subjective quality of their reconstructed content is also evaluated through psychophysical experiments. Furthermore, HEVC and AV1 are compared within a dynamic optimization framework (convex hull rate-distortion optimization) across resolutions with a wider bitrate, using both objective and subjective evaluations. Finally the computational complexities of three tested codecs are compared. The subjective assessments indicate that, for the tested versions there is no significant difference between AV1 and HM, while the tested VTM version shows significant enhancements. The selected source sequences, compressed video content and associated subjective data are available online, offering a resource for compression performance evaluation and objective video quality assessment.},
  annotation    = {VVCå‹ç¼©ç‡æµ‹è¯•30Percent},
  archiveprefix = {arXiv},
  eprint        = {2003.10282},
  eprinttype    = {arxiv},
  file          = {E\:\\Documents\\Zotero\\storage\\XLPBV5A5\\2020 - Comparing VVC, HEVC and AV1 using Objective and Subjective Assessments - Zhang ç­‰ã€‚.pdf},
  journal       = {arXiv:2003.10282 [eess]},
  keywords      = {Electrical Engineering and Systems Science - Image and Video Processing},
  primaryclass  = {eess}
}

@misc{VVCsoftwareVTM,
  title      = {Bossen {{F}}, {{Gallasso M P}}, {{Wieckowski A}}, et al. {{H}}.266/{{VVC VTM Reference Software}} [{{CP}}/{{OL}}]. [2021-02-01]. {{https://vcgit.hhi.fraunhofer.de/jvet/VVCSoftware\_VTM}}},
  abstract   = {VVC VTM reference software},
  annotation = {VVCå‚è€ƒè½¯ä»¶VTM12}
}

@misc{VVCsoftwareVVenC,
  title        = {Wieckowski {{A}}, {{Brandenburg J}}, {{Schmidt L}}, et al. {{Fraunhofer Versatile Video Encoder}} ({{VVenC}}) [{{CP}}/{{OL}}]. [2021-04-28]. {{https://github.com/fraunhoferhhi/vvenc}}},
  abstract     = {Fraunhofer Versatile Video Encoder (VVenC). Contribute to fraunhoferhhi/vvenc development by creating an account on GitHub.},
  copyright    = {View license         ,                 View license},
  howpublished = {Fraunhofer HHI},
  keywords     = {codec,encoder,h266,video,vvc}
}

@inproceedings{VVCTestConditions,
  title      = {{{JVET}} Common Test Conditions and Software Reference Configurations},
  shorttitle = {{{JVET}}-{{J1010}}},
  author     = {Boyce, Jill and Suehring, Karsten and Li, Xiang and Seregin, Vadim},
  year       = {2018},
  month      = jul,
  abstract   = {This document defines common test conditions and software reference configurations to be used in the context of core experiments (CE) conducted after the 10 th JVET meeting. These common test conditions are also recommended for use in technical contributions to the 11 th and following JVET meetings, if applicable.},
  annotation = {VVCæµ‹è¯•é…ç½®},
  file       = {E\:\\Documents\\Zotero\\storage\\J42CZN8R\\2018 - JVET-J1010 JVET common test conditions and software reference configurations - Boyce ç­‰ã€‚.pdf}
}

@article{XiDianIntraPredictionH264,
  title      = {{ä¸€ç§é™ä½é¢„æµ‹æ¨¡å¼å¼€é”€çš„å¸§å†…é¢„æµ‹æ–¹æ³•}},
  author     = {å…ƒè¾‰ and å¸¸ä¹‰æ— and å¢æœé˜³ and ææ˜},
  year       = {2010},
  volume     = {37},
  pages      = {981},
  publisher  = {{è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦å­¦æŠ¥}},
  doi        = {10.3969/j.issn.1001-2400.2010.06.001},
  abstract   = {æå‡ºä¸€ç§æ–°é¢–çš„å¸§å†…é¢„æµ‹æ–¹æ³•ï¼æ¯”è¾ƒæ¯ç§é¢„æµ‹æ¨¡å¼çš„é¢„æµ‹å—ä¸ç›´æµ(DC)é¢„æµ‹æ¨¡å¼çš„é¢„æµ‹å—ä¹‹é—´çš„ç»å¯¹å·®å’Œï¼è¿›è€Œåˆ¤æ–­å½“å‰å—åœ¨å„ç§é¢„æµ‹æ¨¡å¼ä¸‹çš„é¢„æµ‹å—æ˜¯å¦ç›¸ä¼¼ï¼è‹¥å½“å‰å—çš„å„ç§é¢„æµ‹å—éƒ½ç›¸ä¼¼ï¼Œåˆ™å°†æ‰€æœ‰é¢„æµ‹å—çš„å‡å€¼ä½œä¸ºå½“å‰å—çš„æœ€ç»ˆé¢„æµ‹ç»“æœï¼Œä¸”ä¸å¿…ç¼–ç é¢„æµ‹æ¨¡å¼ï¼å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•è¾ƒH.264/AVCèƒ½å¤Ÿè·å¾—æ›´é«˜çš„ç¼–ç æ€§èƒ½ï¼Œåœ¨æ¢å¤è§†é¢‘å®¢è§‚è´¨é‡PSNRç›¸åŒæ—¶ï¼Œç ç‡å¹³å‡ä¸‹é™2.40ï¼…ï¼Œç¼–ç æ—¶é—´å¹³å‡å‡å°‘25.83ï¼…ï¼},
  annotation = {è¥¿ç”µï¼Œä¸éœ€è¦ç¼–ç æ¨¡å¼ä¿¡æ¯çš„å¸§å†…é¢„æµ‹æ–¹å¼},
  eid        = {981},
  file       = {E\:\\Documents\\Zotero\\storage\\IDH579VA\\2010 - ä¸€ç§é™ä½é¢„æµ‹æ¨¡å¼å¼€é”€çš„å¸§å†…é¢„æµ‹æ–¹æ³• - å…ƒè¾‰ ç­‰ã€‚.pdf;E\:\\Documents\\Zotero\\storage\\ZQ56ZYW8\\ä¸€ç§é™ä½é¢„æµ‹æ¨¡å¼å¼€é”€çš„å¸§å†…é¢„æµ‹æ–¹æ³•_å…ƒè¾‰.caj},
  journal    = {è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦å­¦æŠ¥},
  keywords   = {Â¡pÂ¿å¸§å†…é¢„æµ‹,H.264/AVC,æ¨¡å¼ä¿¡æ¯,è§†é¢‘ç¼–ç Â¡/pÂ¿},
  language   = {ä¸­æ–‡},
  number     = {6},
  note       = {doi: 10.3969/j.issn.1001-2400.2010.06.001}
}


